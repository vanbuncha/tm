{"cells":[{"cell_type":"markdown","metadata":{"id":"7e-pWXTBdi5i"},"source":["# Assignment 2 - Data Mining"]},{"cell_type":"markdown","metadata":{"id":"xqI-XewcnizU"},"source":["# Task 1\n","The task one is just to download the W-NUT_data.zip\n","- [X] Done"]},{"cell_type":"markdown","metadata":{"id":"aNbZYiAmnIM5"},"source":["# Task 2\n","Task 2 is to convert IOB data to the correct data structure for token class.\n","- [X] Done"]},{"cell_type":"markdown","metadata":{"id":"hmO5Gtenm2Ay"},"source":["Needed libraries"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":198,"status":"ok","timestamp":1699275682537,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"letndaDnnoxf"},"outputs":[],"source":["# ! pip install transformers\n","# ! pip install datasets\n","# ! pip install seqeval\n","# ! pip install evaluate\n","# ! pip install torch\n","# ! pip install accelerate\n","# ! pip install transformers[torch]\n","\n","# ! pip install optuna\n","# # or $ conda install -c conda-forge optuna\n","\n"]},{"cell_type":"code","execution_count":37,"metadata":{"executionInfo":{"elapsed":15913,"status":"ok","timestamp":1699275698789,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"SL9vX3xnnizW"},"outputs":[],"source":["from datasets import Dataset\n","from transformers import AutoTokenizer\n","import torch\n","import accelerate\n","import evaluate\n","from transformers import DataCollatorForTokenClassification\n","from datasets import DatasetDict\n","from transformers import AutoModelForTokenClassification\n","from huggingface_hub import notebook_login\n","from transformers import TrainingArguments\n","from transformers import Trainer\n","from sklearn.model_selection import ParameterGrid\n","import seqeval\n","from sklearn.metrics import classification_report\n","\n"]},{"cell_type":"markdown","metadata":{"id":"swiP4Hnrm4RA"},"source":["# Importing training set"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":21,"status":"ok","timestamp":1699275698790,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"L0V5PxI1dSi6"},"outputs":[],"source":["# Define the data format\n","data = {\n","    \"tokens\": [],  # List of tokens\n","    \"labels\": [],  # List of integer labels\n","}\n","\n","label_to_int = {}  # Dictionary to map original labels to integers\n","label_names = []  # List to map integers to original labels\n","\n","train_path = \"W-NUT_data/wnut17train.conll\"\n","\n","\n","# Read the .conll file and populate the data dictionary\n","with open(train_path, \"r\") as file:\n","    lines = file.readlines()\n","    tokens, labels = [], []\n","    for line in lines:\n","        parts = line.strip().split()\n","        if parts:\n","            token, label = parts\n","            tokens.append(token)\n","\n","            # Check if the label is already in the mapping dictionary\n","            if label not in label_to_int:\n","                label_to_int[label] = len(label_to_int)\n","                label_names.append(label)\n","\n","            labels.append(label_to_int[label])\n","        else:\n","            data[\"tokens\"].append(tokens)\n","            data[\"labels\"].append(labels)\n","            tokens, labels = [], []  # Reset for the next sentence\n","\n","# Create a custom dataset\n","train = Dataset.from_dict(data)"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1699275698790,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"SMSvk7jyjjBN","outputId":"bc6c0e82-3157-4dc1-dbd9-9017054d997f"},"outputs":[],"source":["print(train)"]},{"cell_type":"markdown","metadata":{"id":"agXOqxchm7aY"},"source":["# Importing validation set"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1699275698790,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"KmDuvrUbYUno"},"outputs":[],"source":["# Define the data format for the validation set\n","validation_data = {\n","    \"tokens\": [],  # List of tokens\n","    \"labels\": [],  # List of integer labels\n","}\n","\n","validation_path = \"W-NUT_data/emerging.dev.conll\"  # Replace with the actual path to your validation set .conll file\n","\n","# Read the .conll file for the validation set and populate the data dictionary\n","with open(validation_path, \"r\") as file:\n","    lines = file.readlines()\n","    tokens, labels = [], []\n","    for line in lines:\n","        parts = line.strip().split()\n","        if len(parts) == 2:  # Check if there are both token and label\n","            token, label = parts\n","            tokens.append(token)\n","\n","            if label not in label_to_int:\n","                label_to_int[label] = len(label_names)\n","                label_names.append(label)\n","\n","            labels.append(label_to_int[label])\n","        else:\n","            if parts:  # Handle lines with only one value\n","                # Decide how to handle lines with one value (e.g., set a default label)\n","                token = parts[0]\n","                label = \"O\"  # You can replace this with an appropriate default label\n","                tokens.append(token)\n","\n","                if label not in label_to_int:\n","                    label_to_int[label] = len(label_names)\n","                    label_names.append(label)\n","\n","                labels.append(label_to_int[label])\n","            else:\n","                validation_data[\"tokens\"].append(tokens)\n","                validation_data[\"labels\"].append(labels)\n","                tokens, labels = [], []  # Reset for the next sentence\n","\n","# If there's data left to process\n","if tokens:\n","    validation_data[\"tokens\"].append(tokens)\n","    validation_data[\"labels\"].append(labels)\n","\n","# Create a custom dataset for the validation set\n","validation = Dataset.from_dict(validation_data)\n"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699275698790,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"ZUUw-Y_0e98b","outputId":"60b08b7f-abb4-4593-fefb-14df753982a7"},"outputs":[],"source":["print(validation)"]},{"cell_type":"markdown","metadata":{"id":"LRYmQgsjnARd"},"source":["# Importing test set"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":352,"status":"ok","timestamp":1699275699139,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"qHpDRhBoj8cB"},"outputs":[],"source":["# Define the data format for the test set\n","test_data = {\n","   \"tokens\": [],  # List of tokens\n","   \"labels\": [],  # List of integer labels\n","}\n","\n","test_path = \"W-NUT_data/emerging.test.annotated\"  # Replace with the actual path to your test set .conll file\n","\n","# Read the .conll file for the test set and populate the data dictionary\n","with open(test_path, \"r\") as file:\n","   lines = file.readlines()\n","   tokens, labels = [], []\n","   for line in lines:\n","       parts = line.strip().split()\n","       if len(parts) == 2:  # Check if there are both token and label\n","           token, label = parts\n","           tokens.append(token)\n","\n","           if label not in label_to_int:\n","               label_to_int[label] = len(label_names)\n","               label_names.append(label)\n","\n","           labels.append(label_to_int[label])\n","       else:\n","           if parts:  # Handle lines with only one value\n","               # Decide how to handle lines with one value (e.g., set a default label)\n","               token = parts[0]\n","               label = \"O\"  # You can replace this with an appropriate default label\n","               tokens.append(token)\n","\n","               if label not in label_to_int:\n","                   label_to_int[label] = len(label_names)\n","                   label_names.append(label)\n","\n","               labels.append(label_to_int[label])\n","           else:\n","               test_data[\"tokens\"].append(tokens)\n","               test_data[\"labels\"].append(labels)\n","               tokens, labels = [], []  # Reset for the next sentence\n","\n","# If there's data left to process\n","if tokens:\n","   test_data[\"tokens\"].append(tokens)\n","   test_data[\"labels\"].append(labels)\n","\n","# Create a custom dataset for the test set\n","test = Dataset.from_dict(test_data)\n"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1699275699140,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"AkDFnjFFj-iG","outputId":"43f6f14e-e17a-439a-c1e3-7d7c24305951"},"outputs":[],"source":["print(test)"]},{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1699275699140,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"RVcphvQQonBZ","outputId":"d73e3967-aeaf-419d-bae3-0f2cd59c30b9"},"outputs":[],"source":["print(label_to_int)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699275699140,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"9d3Q11jvqOd2","outputId":"2acfc3c7-87f7-4a57-8748-a2a6b09f004c"},"outputs":[],"source":["print(label_names)"]},{"cell_type":"markdown","metadata":{"id":"ALwL5apknC-O"},"source":["# Realizing a dataset dictionary"]},{"cell_type":"code","execution_count":46,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699275699140,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"oaW-JRDxkfVr"},"outputs":[],"source":["raw_datasets = DatasetDict({\n","    'train': train,\n","    'validation': validation,\n","    'test': test\n","})"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699275699140,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"b7Kc5p5dlVKd","outputId":"2311819f-8313-4d7a-c0b0-3a97a25979e7"},"outputs":[],"source":["print(raw_datasets)"]},{"cell_type":"markdown","metadata":{"id":"or8-qlGJmvvU"},"source":["# Verify the initial alignment between tokens and labels."]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1699275699140,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"LkxFkSP8mT5m","outputId":"c825fcc9-ae2e-4432-c49a-f0c38e59d23d"},"outputs":[],"source":["words = raw_datasets[\"train\"][0][\"tokens\"]\n","labels = raw_datasets[\"train\"][0][\"labels\"]\n","line1 = \"\"\n","line2 = \"\"\n","for word, label in zip(words, labels):\n","    full_label = label_names[label]\n","    max_length = max(len(word), len(full_label))\n","    line1 += word + \" \" * (max_length - len(word) + 1)\n","    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n","\n","print(line1)\n","print(line2)"]},{"cell_type":"markdown","metadata":{"id":"h8vFB1ofnfqV"},"source":["# Importing the needed tokenizer"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":267,"status":"ok","timestamp":1699275699404,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"olUqne2NneG1"},"outputs":[],"source":["model_checkpoint = \"bert-base-cased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1699275699405,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"KSwKdpQsD3JD","outputId":"0c040f87-196b-4cc3-c309-69898b79ac2c"},"outputs":[{"data":{"text/plain":["['[CLS]',\n"," '@',\n"," 'p',\n"," '##aul',\n"," '##walk',\n"," 'It',\n"," \"'\",\n"," 's',\n"," 'the',\n"," 'view',\n"," 'from',\n"," 'where',\n"," 'I',\n"," \"'\",\n"," 'm',\n"," 'living',\n"," 'for',\n"," 'two',\n"," 'weeks',\n"," '.',\n"," 'Empire',\n"," 'State',\n"," 'Building',\n"," '=',\n"," 'E',\n"," '##SB',\n"," '.',\n"," 'Pretty',\n"," 'bad',\n"," 'storm',\n"," 'here',\n"," 'last',\n"," 'evening',\n"," '.',\n"," '[SEP]']"]},"execution_count":50,"metadata":{},"output_type":"execute_result"}],"source":["inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n","inputs.tokens()"]},{"cell_type":"markdown","metadata":{"id":"l5q39tLcy56h"},"source":["# Defining the function to align labels and tokens properly"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699275699405,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"RhTJjytaoNyj"},"outputs":[],"source":["def align_labels_with_tokens(labels, word_ids):\n","    new_labels = []\n","    current_word = None\n","    for word_id in word_ids:\n","        if word_id != current_word:\n","            # Start of a new word!\n","            current_word = word_id\n","            label = -100 if word_id is None else labels[word_id]\n","            new_labels.append(label)\n","        elif word_id is None:\n","            # Special token\n","            new_labels.append(-100)\n","        else:\n","            # Same word as previous token\n","            label = labels[word_id]\n","            # If the label is B-XXX we change it to I-XXX\n","            if label % 2 == 1:\n","                label += 1\n","            new_labels.append(label)\n","\n","    return new_labels"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699275699405,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"_ik9DoJCoT3F","outputId":"e0687bc3-d763-49e0-b9d7-3b4c556bd495"},"outputs":[],"source":["labels = raw_datasets[\"train\"][0][\"labels\"]\n","word_ids = inputs.word_ids()\n","print(labels)\n","print(align_labels_with_tokens(labels, word_ids))"]},{"cell_type":"markdown","metadata":{"id":"vbAwxSwwzAnS"},"source":["Defining the function to apply the previous function on all the dataset"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":248,"status":"ok","timestamp":1699275699650,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"qTVIwwPNfTDm"},"outputs":[],"source":["def tokenize_and_align_labels(examples):\n","    tokenized_inputs = tokenizer(\n","        examples[\"tokens\"], truncation=True, is_split_into_words=True\n","    )\n","    all_labels = examples[\"labels\"]\n","    new_labels = []\n","    for i, labels in enumerate(all_labels):\n","        word_ids = tokenized_inputs.word_ids(i)\n","        new_labels.append(align_labels_with_tokens(labels, word_ids))\n","\n","    tokenized_inputs[\"labels\"] = new_labels\n","    return tokenized_inputs"]},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["cd865b8b967b4fa68ae67b825afa9978","20336a9b683643348df644c68fc123ac","b75715e40b904e048c0a4314eadd41eb","4318d59a725842dd8e7d71df077a129c","a4b0e51d168e4c62b6daa9671eca21b2","a20e59edf8764338bcb9bd59cb60ad3f","ef06580993bb42779ef7028dfa33cd67","20df35f6fce148b08032e1674e4653ef","08efea0cab4e4ee7aa39cbbaf9486df2","686b84fa6d244287a714d686a6c965dc","e570a9ca0ba541b38adc118c995bb979","7070de3dd1604851b46bb1e6fa93f89a","9c2175d0b13a44ea9877928297a2886b","fccd3e0011d340048a2055b673cf2f81","dcfde0e4214344c5a341dfc72295cf05","a70acbe6f5c8405c9843b09d1edf3970","2119f9c3f36e490d8bcdac326ef46e81","c5cd5acf42334b66b917eedb1e40635b","cae4590e5d564254957207fdfae071a2","6c03912dfa7247418ae4f1507d25f030","e3bc0d3e70704170bcd98f29a0d306bc","ba05ea5c28ab4d898dc44c28939798bc","4ab3c5e6542441c0849ce5288d10dd94","a6099f4f07824d7aa99b0cbbba4c2fcd","6b814cadc489493aae69d0fa3ec6551f","af271bad93c243c7b8d9e812e402ebec","5eb959b3607845cf8f0bcba2ad11a7ab","b198a9a47de8437d84e793f6ad9f19a5","4a1aaabfc8314220bfe963384eb126e5","9cfc0cc7c3d44de08fcf82934b17a66e","8c60019140b24a21aaaa6564b030b93d","4f3f9bad30224826a6a620bb391312d9","66a887bd9fee454dbe5adb6959471a49"]},"executionInfo":{"elapsed":2969,"status":"ok","timestamp":1699275702612,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"znADGrKyfmhb","outputId":"2d1f389c-d1c0-4ffa-fbdf-f30b186e4a94"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5b378393c6624b6680a99f8427c11a52","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/3394 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f8480bf5b65944d68aa97dbf2b9b2c31","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1009 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"36078871486d4e188d737caa6e0c2774","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1287 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_datasets = raw_datasets.map(\n","    tokenize_and_align_labels,\n","    batched=True,\n","    remove_columns=raw_datasets[\"train\"].column_names,\n",")"]},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1699275702612,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"SnklnCk2xOBD","outputId":"bcfbe5b9-b00e-4718-f23e-f607608051eb"},"outputs":[],"source":["print(tokenized_datasets)"]},{"cell_type":"markdown","metadata":{"id":"9BlCHEIcrHLP"},"source":["Data collation"]},{"cell_type":"code","execution_count":56,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699275702612,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"maOLtLrarKNi"},"outputs":[],"source":["data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1699275702612,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"uVs3KisirM_u","outputId":"8469754f-d7ea-4347-e724-d5db0e261841"},"outputs":[{"name":"stderr","output_type":"stream","text":["You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/plain":["tensor([[-100,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    1,    2,    2,    0,\n","            1,    2,    0,    0,    0,    0,    0,    0,    0,    0, -100],\n","        [-100,    0,    0,    0,    0,    0,    0,    3,    4,    4,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0, -100, -100]])"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n","batch[\"labels\"]"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1699275702612,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"OgMnLaWsrRE4","outputId":"8fe2f479-3946-460d-d1ab-b9f41b0fc80a"},"outputs":[],"source":["for i in range(2):\n","    print(tokenized_datasets[\"train\"][i][\"labels\"])"]},{"cell_type":"markdown","metadata":{"id":"ZoT4KrAp0doI"},"source":["# Task 3\n","Evaluation and metrics"]},{"cell_type":"code","execution_count":59,"metadata":{"executionInfo":{"elapsed":824,"status":"ok","timestamp":1699275703433,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"5HXph9ej0khm"},"outputs":[],"source":["metric = evaluate.load(\"seqeval\")"]},{"cell_type":"code","execution_count":60,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699275703433,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"IYuAyQFm124I"},"outputs":[],"source":["import numpy as np\n","\n","\n","def compute_metrics(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # Remove ignored index (special tokens) and convert to labels\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    true_predictions = [\n","        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n","    return {\n","        \"precision\": all_metrics[\"overall_precision\"],\n","        \"recall\": all_metrics[\"overall_recall\"],\n","        \"f1\": all_metrics[\"overall_f1\"],\n","        \"accuracy\": all_metrics[\"overall_accuracy\"],\n","    }"]},{"cell_type":"markdown","metadata":{"id":"7NMSPSWw2puH"},"source":["# Task 4"]},{"cell_type":"code","execution_count":61,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699275703433,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"FD2UiffV5rto"},"outputs":[],"source":["id2label = {i: label for i, label in enumerate(label_names)}\n","label2id = {v: k for k, v in id2label.items()}\n"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3707,"status":"ok","timestamp":1699275707138,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"RL5jxJw354mF","outputId":"55d38fe6-3e4e-4a20-967a-39f999739f21"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["model = AutoModelForTokenClassification.from_pretrained(\n","    model_checkpoint,\n","    id2label=id2label,\n","    label2id=label2id,\n",")"]},{"cell_type":"code","execution_count":63,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1699275707138,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"8oldRMl84Qoa","outputId":"0ace979c-be9e-4cfb-bcaf-d43fb65ac8ca"},"outputs":[{"data":{"text/plain":["13"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["model.config.num_labels"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["5ae3da8b1af94657a5149b0f046accda","3beb5812aba344caac21533a424534a5","710d2fdc396a4788b8e68fedb8d8bd06","fbe726a3c52240d096d2f3dd6f164333","cbec063e98d04d33822df13c386021e2","b49a110f519c4506807410efa183c864","9c4f0084cc6d4ae788ef83cc72ce323c","b8bed15f7fe1457b85cb56f0205cc6ce","a3d95dd667a748169088614179227117","42a42f73b163476dbd789ee0c679a51b","18f0209dfd2d4f71a61cff974aae5da5","b2e2df2f59824e838a04468bdc567a68","6c9b49cbe7b941cba170034d8f3f24ab","6c755fb412624b809d1f2de97fc591b9","2edbf105a692434eab996204affb1f87","52c0866d7a664e25afdc2f87648fc17b","5406b0025a7a49408d6a179d19fb38dc","86d5d1ee288941818bb77eb4d66d7d67","ab7d5f51566740d08351e5beff9f3534","713c6e2c9c8b44cb8b3a4c1ac2c2e615","93d00b2635b3450a84db556c4a175e89","5653ac6638d64703b148f2683afab99f","dcb9947e55d8480a8b800937731fb384","121c674a665b4948b2b903e653737450","d612714f76b54d128e96b41ba56dce80","5228b938a5af4ede8c9b5a8c48f5805e","b99690a237c340359256bcd521a9ccac","200a35f4004544f8a2f384feae489636","d62e1749d1a44eb6825ec3f46b3651f9","b22e69dc22f542a2a022f5c1f648607b","a22a4582dd464aa9869748436347358f","021f4c6999d1477688b3061e15d19336"]},"executionInfo":{"elapsed":369,"status":"ok","timestamp":1699275720739,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"GA3i8phK59DO","outputId":"1b5c4c44-32f5-45c7-9289-c29fef282199"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"06f5267d692445d793516eb02f22ce57","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["notebook_login() #reading token"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["af42b8e33657455c9fe793d3c53a993b","29e200b20e074ad1b546742bfb1bbece","ca1f51909bd54526a84e9b4814a12f71","9fa399ff818b4b8d91c1ae1b566990b6","c106d63563c84fcf91c07f6a6f3b3199","21af6a41e3734646a874bdad2ca5a158","210181f7497a47c0a539ff0900bc40a7","d72399f9abf24905ad6236456099eb02","eaa673163fbd42128d480190bc7c53da","dba2514b49304ff1b0c39390a836f5f0","2087c04b93f3460583185651885eac95","b285da0dbc044b70a389be7456b24fbc","12d46c6c85c04096a78d782c0a93723b","6ac6ee23163c43b59dc5f13373ea397a","13c8168776c34da4858c6d678475e010","5f29d32431064fa2abaeba808c6fbc7e","dbed1899815646279af9ea1669431571","deabb55f665d4cee9234564c90a7911f","fb248e41a08d4c5f94a207ed9c2eb8d5","79af72e64fcb4c34bba1d9396e392195","33ec04869b82415f96c94198e95c361a","317ad3998a1746eb9523b018f41acff6","abe09dad02ac417da4191eaac66f8a86","a3b9fc0503ab428bac43634b7cb6e3ec","8a9e3461c0fc416986f42753e242e28d","b33ee0b53a264d198a7f6bf64fcd14e8","587d3e7d8ec14e9b85945916ccbe0829","8ef27ef18f3745c8a4b472b79c279cab","4d96f407a9334e12aaf320c241d39f37","4ba999c38b9e4343adb3ab300766eb5f","74d33f3a596a41c2b0b1fde6a9a6afd2","025a65adc4d44471a940bb9438f94a01"]},"executionInfo":{"elapsed":431,"status":"ok","timestamp":1699275730332,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"ekKUuhFA-nwX","outputId":"73c04517-477d-4e46-80be-6eb70303bad2"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1edee73e6a0448d0b3b9ddaa5cb2cf3d","version_major":2,"version_minor":0},"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"]},"metadata":{},"output_type":"display_data"}],"source":["notebook_login() # writting token"]},{"cell_type":"code","execution_count":88,"metadata":{"executionInfo":{"elapsed":277,"status":"ok","timestamp":1699275737148,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"_0gFWnD16QjD"},"outputs":[],"source":["args = TrainingArguments(\n","    \"bert-finetuned-ner\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    push_to_hub=True,\n",")"]},{"cell_type":"code","execution_count":89,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":498},"executionInfo":{"elapsed":108273,"status":"error","timestamp":1699279656229,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"HSTKK-OeE3Yq","outputId":"95ecb6fa-1ea5-4eef-a454-6cbaba62b645","scrolled":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6aece1db3ed84e29ad970e09b8a16bca","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1275 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"RuntimeError","evalue":"MPS backend out of memory (MPS allocated: 3.29 GB, other allocations: 14.77 GB, max allowed: 18.13 GB). Tried to allocate 84.95 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m/Users/vanbuncha/devenv/leidenuniv/tm/as2/Assignment_2_Text_Mining.ipynb Cell 47\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vanbuncha/devenv/leidenuniv/tm/as2/Assignment_2_Text_Mining.ipynb#Y220sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vanbuncha/devenv/leidenuniv/tm/as2/Assignment_2_Text_Mining.ipynb#Y220sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vanbuncha/devenv/leidenuniv/tm/as2/Assignment_2_Text_Mining.ipynb#Y220sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     args\u001b[39m=\u001b[39margs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vanbuncha/devenv/leidenuniv/tm/as2/Assignment_2_Text_Mining.ipynb#Y220sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     tokenizer\u001b[39m=\u001b[39mtokenizer,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vanbuncha/devenv/leidenuniv/tm/as2/Assignment_2_Text_Mining.ipynb#Y220sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vanbuncha/devenv/leidenuniv/tm/as2/Assignment_2_Text_Mining.ipynb#Y220sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n","File \u001b[0;32m~/anaconda3/envs/tm_as2/lib/python3.10/site-packages/transformers/trainer.py:1546\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1543\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     \u001b[39m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1545\u001b[0m     hf_hub_utils\u001b[39m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1546\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1547\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1548\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1549\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1550\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1551\u001b[0m     )\n\u001b[1;32m   1552\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   1553\u001b[0m     hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n","File \u001b[0;32m~/anaconda3/envs/tm_as2/lib/python3.10/site-packages/transformers/trainer.py:1916\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1914\u001b[0m     optimizer_was_run \u001b[39m=\u001b[39m scale_before \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m scale_after\n\u001b[1;32m   1915\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1916\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m   1917\u001b[0m     optimizer_was_run \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39moptimizer_step_was_skipped\n\u001b[1;32m   1919\u001b[0m \u001b[39mif\u001b[39;00m optimizer_was_run:\n\u001b[1;32m   1920\u001b[0m     \u001b[39m# Delay optimizer scheduling until metrics are generated\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/tm_as2/lib/python3.10/site-packages/accelerate/optimizer.py:145\u001b[0m, in \u001b[0;36mAcceleratedOptimizer.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_accelerate_step_called \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 145\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer\u001b[39m.\u001b[39;49mstep(closure)\n","File \u001b[0;32m~/anaconda3/envs/tm_as2/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:68\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     66\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     67\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n","File \u001b[0;32m~/anaconda3/envs/tm_as2/lib/python3.10/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m~/anaconda3/envs/tm_as2/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n","File \u001b[0;32m~/anaconda3/envs/tm_as2/lib/python3.10/site-packages/torch/optim/adamw.py:184\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    171\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    173\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    174\u001b[0m         group,\n\u001b[1;32m    175\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m         state_steps,\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 184\u001b[0m     adamw(\n\u001b[1;32m    185\u001b[0m         params_with_grad,\n\u001b[1;32m    186\u001b[0m         grads,\n\u001b[1;32m    187\u001b[0m         exp_avgs,\n\u001b[1;32m    188\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    189\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    190\u001b[0m         state_steps,\n\u001b[1;32m    191\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    192\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    193\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    194\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    195\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    196\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    197\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    198\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    199\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    200\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    201\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m\"\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m    202\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    203\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    206\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n","File \u001b[0;32m~/anaconda3/envs/tm_as2/lib/python3.10/site-packages/torch/optim/adamw.py:335\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adamw\n\u001b[0;32m--> 335\u001b[0m func(\n\u001b[1;32m    336\u001b[0m     params,\n\u001b[1;32m    337\u001b[0m     grads,\n\u001b[1;32m    338\u001b[0m     exp_avgs,\n\u001b[1;32m    339\u001b[0m     exp_avg_sqs,\n\u001b[1;32m    340\u001b[0m     max_exp_avg_sqs,\n\u001b[1;32m    341\u001b[0m     state_steps,\n\u001b[1;32m    342\u001b[0m     amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    343\u001b[0m     beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    344\u001b[0m     beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    345\u001b[0m     lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    346\u001b[0m     weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    347\u001b[0m     eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    348\u001b[0m     maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    349\u001b[0m     capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    350\u001b[0m     differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    351\u001b[0m     grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    352\u001b[0m     found_inf\u001b[39m=\u001b[39;49mfound_inf,\n\u001b[1;32m    353\u001b[0m )\n","File \u001b[0;32m~/anaconda3/envs/tm_as2/lib/python3.10/site-packages/torch/optim/adamw.py:464\u001b[0m, in \u001b[0;36m_single_tensor_adamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    462\u001b[0m         denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    463\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m         denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    466\u001b[0m     param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n\u001b[1;32m    468\u001b[0m \u001b[39m# Lastly, switch back to complex view\u001b[39;00m\n","\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 3.29 GB, other allocations: 14.77 GB, max allowed: 18.13 GB). Tried to allocate 84.95 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."]}],"source":["trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n",")\n","trainer.train()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"executionInfo":{"elapsed":223955,"status":"ok","timestamp":1699279905953,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"C1Mn7m8gnizg","outputId":"ccfb0ea8-0538-41a3-e665-3a16ca19c62d"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1275' max='1275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1275/1275 03:21, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.880355</td>\n","      <td>0.523810</td>\n","      <td>0.214345</td>\n","      <td>0.304207</td>\n","      <td>0.928543</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.001600</td>\n","      <td>0.986134</td>\n","      <td>0.557962</td>\n","      <td>0.181592</td>\n","      <td>0.274007</td>\n","      <td>0.928141</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.001500</td>\n","      <td>0.972839</td>\n","      <td>0.564838</td>\n","      <td>0.187811</td>\n","      <td>0.281892</td>\n","      <td>0.928191</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='161' max='161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [161/161 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test Results: {'eval_loss': 0.9728385210037231, 'eval_precision': 0.5648379052369077, 'eval_recall': 0.18781094527363185, 'eval_f1': 0.28189172370877413, 'eval_accuracy': 0.9281909547738694, 'eval_runtime': 6.2486, 'eval_samples_per_second': 205.966, 'eval_steps_per_second': 25.766, 'epoch': 3.0}\n"]}],"source":["args = TrainingArguments(\n","    \"bert-finetuned-ner\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    push_to_hub=True,\n",")\n","\n","# Create Trainer with the current model and arguments\n","trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],  # Use the test set for evaluation during training\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n",")\n","\n","# Train the model with the current hyperparameters\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print and/or store the results for this hyperparameter combination\n","print(f\"Test Results: {test_results}\")\n"]},{"cell_type":"markdown","metadata":{"id":"aL2PEVW7nizg"},"source":["# Task 5 Hyperparameters tuning\n","Tuning learning rate and batch size with gradient accumulation because of GPU memory problems."]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"elapsed":280976,"status":"ok","timestamp":1699278036252,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"X1QdHugkqU9G","outputId":"7656ff24-3fb9-415c-c560-c8fec855e80e"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2547' max='2547' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2547/2547 04:19, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.020400</td>\n","      <td>0.889384</td>\n","      <td>0.680328</td>\n","      <td>0.315190</td>\n","      <td>0.430796</td>\n","      <td>0.915868</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.021300</td>\n","      <td>0.805429</td>\n","      <td>0.668213</td>\n","      <td>0.364557</td>\n","      <td>0.471744</td>\n","      <td>0.917046</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.009000</td>\n","      <td>0.720928</td>\n","      <td>0.697917</td>\n","      <td>0.381646</td>\n","      <td>0.493453</td>\n","      <td>0.921327</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='161' max='161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [161/161 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test Results:\n","{'eval_loss': 0.7523127198219299, 'eval_precision': 0.5814249363867684, 'eval_recall': 0.189469320066335, 'eval_f1': 0.2858036272670419, 'eval_accuracy': 0.929321608040201, 'eval_runtime': 6.2163, 'eval_samples_per_second': 207.037, 'eval_steps_per_second': 25.9, 'epoch': 3.0}\n"]}],"source":["args_combination_1 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-1\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=1e-4,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=4,\n","    push_to_hub=True,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_1,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],  # Use the \"validation\" set for hyperparameter optimization\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"elapsed":192419,"status":"ok","timestamp":1699278228669,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"39z8bT9Cv2Yw","outputId":"ee9529f9-a992-457c-d4eb-cc0347f2d538"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='849' max='849' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [849/849 02:53, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.847894</td>\n","      <td>0.670058</td>\n","      <td>0.291772</td>\n","      <td>0.406526</td>\n","      <td>0.913085</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.013500</td>\n","      <td>0.622215</td>\n","      <td>0.675138</td>\n","      <td>0.386709</td>\n","      <td>0.491751</td>\n","      <td>0.920739</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.013500</td>\n","      <td>0.652038</td>\n","      <td>0.658026</td>\n","      <td>0.417722</td>\n","      <td>0.511034</td>\n","      <td>0.923307</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='161' max='161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [161/161 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test Results:\n","{'eval_loss': 0.7375848889350891, 'eval_precision': 0.5557986870897156, 'eval_recall': 0.21061359867330018, 'eval_f1': 0.30547203848466625, 'eval_accuracy': 0.9295477386934673, 'eval_runtime': 6.8643, 'eval_samples_per_second': 187.492, 'eval_steps_per_second': 23.455, 'epoch': 3.0}\n"]}],"source":["args_combination_2 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-2\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=1e-4,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=12,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_2,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],  # Use the \"validation\" set for hyperparameter optimization\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"elapsed":276227,"status":"ok","timestamp":1699278504878,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"SmBpcMfPv8S1","outputId":"2f9e417e-1984-44e4-8e3b-5198761bf5de"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2547' max='2547' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2547/2547 04:15, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.007900</td>\n","      <td>0.912543</td>\n","      <td>0.693935</td>\n","      <td>0.311392</td>\n","      <td>0.429882</td>\n","      <td>0.916350</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.005700</td>\n","      <td>0.823483</td>\n","      <td>0.711230</td>\n","      <td>0.336709</td>\n","      <td>0.457045</td>\n","      <td>0.917688</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.005900</td>\n","      <td>0.730988</td>\n","      <td>0.681406</td>\n","      <td>0.380380</td>\n","      <td>0.488221</td>\n","      <td>0.920953</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='161' max='161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [161/161 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test Results:\n","{'eval_loss': 0.8010109066963196, 'eval_precision': 0.5705596107055961, 'eval_recall': 0.19444444444444445, 'eval_f1': 0.29004329004329005, 'eval_accuracy': 0.9292713567839196, 'eval_runtime': 6.8971, 'eval_samples_per_second': 186.599, 'eval_steps_per_second': 23.343, 'epoch': 3.0}\n"]}],"source":["args_combination_3 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-3\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=4,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_3,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],  # Use the \"validation\" set for hyperparameter optimization\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"elapsed":190807,"status":"ok","timestamp":1699278695670,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"PJikXVzrwDlE","outputId":"f6fdfb47-fd46-47d8-99b2-c94c41573827"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='849' max='849' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [849/849 02:45, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.859605</td>\n","      <td>0.712379</td>\n","      <td>0.371519</td>\n","      <td>0.488353</td>\n","      <td>0.920257</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.003900</td>\n","      <td>0.706297</td>\n","      <td>0.664888</td>\n","      <td>0.394304</td>\n","      <td>0.495034</td>\n","      <td>0.921916</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.003900</td>\n","      <td>0.662699</td>\n","      <td>0.643917</td>\n","      <td>0.412025</td>\n","      <td>0.502509</td>\n","      <td>0.924699</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='161' max='161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [161/161 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test Results:\n","{'eval_loss': 0.7843152284622192, 'eval_precision': 0.5411764705882353, 'eval_recall': 0.20978441127694858, 'eval_f1': 0.3023603226770242, 'eval_accuracy': 0.9294221105527638, 'eval_runtime': 6.4846, 'eval_samples_per_second': 198.469, 'eval_steps_per_second': 24.828, 'epoch': 3.0}\n"]}],"source":["args_combination_4 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-4\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=12,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_4,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],  # Use the \"validation\" set for hyperparameter optimization\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"elapsed":279380,"status":"ok","timestamp":1699278975032,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"CmEkQahIwKRn","outputId":"a52a4a46-ea54-4f11-9891-d403012b680e"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='2547' max='2547' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2547/2547 04:15, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.002400</td>\n","      <td>0.857778</td>\n","      <td>0.661905</td>\n","      <td>0.351899</td>\n","      <td>0.459504</td>\n","      <td>0.919026</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.001600</td>\n","      <td>0.860201</td>\n","      <td>0.651672</td>\n","      <td>0.357595</td>\n","      <td>0.461790</td>\n","      <td>0.919347</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.001600</td>\n","      <td>0.845222</td>\n","      <td>0.657778</td>\n","      <td>0.374684</td>\n","      <td>0.477419</td>\n","      <td>0.920685</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='161' max='161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [161/161 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test Results:\n","{'eval_loss': 0.8803117275238037, 'eval_precision': 0.5288888888888889, 'eval_recall': 0.19734660033167495, 'eval_f1': 0.28743961352657005, 'eval_accuracy': 0.9284673366834171, 'eval_runtime': 6.1025, 'eval_samples_per_second': 210.896, 'eval_steps_per_second': 26.382, 'epoch': 3.0}\n"]}],"source":["args_combination_5 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-5\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=4,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_5,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],  # Use the \"validation\" set for hyperparameter optimization\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"elapsed":189066,"status":"ok","timestamp":1699279164080,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"4WQaX8e2wOGd","outputId":"dfd440e1-866f-41cb-8ada-1bef4a9c1fbe"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='849' max='849' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [849/849 02:49, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.862558</td>\n","      <td>0.685979</td>\n","      <td>0.374684</td>\n","      <td>0.484650</td>\n","      <td>0.921274</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.001500</td>\n","      <td>0.970584</td>\n","      <td>0.675776</td>\n","      <td>0.344304</td>\n","      <td>0.456184</td>\n","      <td>0.918170</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.001500</td>\n","      <td>0.945845</td>\n","      <td>0.691624</td>\n","      <td>0.344937</td>\n","      <td>0.460304</td>\n","      <td>0.918384</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='161' max='161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [161/161 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test Results:\n","{'eval_loss': 0.9369379281997681, 'eval_precision': 0.5826558265582655, 'eval_recall': 0.17827529021558872, 'eval_f1': 0.273015873015873, 'eval_accuracy': 0.9279396984924623, 'eval_runtime': 6.1735, 'eval_samples_per_second': 208.471, 'eval_steps_per_second': 26.079, 'epoch': 3.0}\n"]}],"source":["args_combination_6 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-6\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=12,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_6,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],  # Use the \"validation\" set for hyperparameter optimization\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"elapsed":195657,"status":"ok","timestamp":1699279359720,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"gcpy4_Qwz3NL","outputId":"2c06b1dc-8bf1-4122-ffe9-0b5bb0b8d0c5"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='849' max='849' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [849/849 02:54, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.934225</td>\n","      <td>0.675386</td>\n","      <td>0.359494</td>\n","      <td>0.469228</td>\n","      <td>0.920471</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.001100</td>\n","      <td>0.971665</td>\n","      <td>0.698473</td>\n","      <td>0.347468</td>\n","      <td>0.464074</td>\n","      <td>0.919294</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.001100</td>\n","      <td>1.008281</td>\n","      <td>0.698241</td>\n","      <td>0.326582</td>\n","      <td>0.445019</td>\n","      <td>0.917367</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='161' max='161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [161/161 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test Results:\n","{'eval_loss': 0.96390700340271, 'eval_precision': 0.5740479548660085, 'eval_recall': 0.16873963515754561, 'eval_f1': 0.26081384171739824, 'eval_accuracy': 0.9278643216080402, 'eval_runtime': 6.9263, 'eval_samples_per_second': 185.815, 'eval_steps_per_second': 23.245, 'epoch': 3.0}\n"]}],"source":["args_combination_7 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-7\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=1e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=4,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_6,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],  # Use the \"validation\" set for hyperparameter optimization\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":244},"executionInfo":{"elapsed":187649,"status":"ok","timestamp":1699279547351,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"AHy-8eWXzrNr","outputId":"13baab88-52cb-46de-ee71-0f3a06e42b60"},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='849' max='849' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [849/849 02:47, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>1.187177</td>\n","      <td>0.721154</td>\n","      <td>0.332278</td>\n","      <td>0.454939</td>\n","      <td>0.917420</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.000300</td>\n","      <td>1.025149</td>\n","      <td>0.676259</td>\n","      <td>0.356962</td>\n","      <td>0.467274</td>\n","      <td>0.919829</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.000300</td>\n","      <td>1.020509</td>\n","      <td>0.698765</td>\n","      <td>0.358228</td>\n","      <td>0.473640</td>\n","      <td>0.919615</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='161' max='161' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [161/161 00:05]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Test Results:\n","{'eval_loss': 1.0025056600570679, 'eval_precision': 0.5787401574803149, 'eval_recall': 0.1828358208955224, 'eval_f1': 0.277882797731569, 'eval_accuracy': 0.9282412060301507, 'eval_runtime': 6.4262, 'eval_samples_per_second': 200.275, 'eval_steps_per_second': 25.054, 'epoch': 3.0}\n"]}],"source":["args_combination_8 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-8\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=1e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=12,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_6,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"validation\"],  # Use the \"validation\" set for hyperparameter optimization\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"markdown","metadata":{"id":"Qs5eBzt0nizi"},"source":["# Task 6"]},{"cell_type":"code","execution_count":66,"metadata":{"executionInfo":{"elapsed":187,"status":"ok","timestamp":1699280802859,"user":{"displayName":"Van Nguyen","userId":"08365009281995599126"},"user_tz":-60},"id":"eX--Un1onizi"},"outputs":[],"source":["import numpy as np\n","from seqeval.metrics import classification_report\n","\n","# Define the list of entity types (label names)\n","label_names = [\n","    \"O\", \n","    \"B-location\", \"I-location\", \n","    \"B-group\", \"I-group\", \n","    \"B-corporation\", \"I-corporation\", \n","    \"B-person\", \"I-person\", \n","    \"B-creative-work\", \"I-creative-work\", \n","    \"B-product\", \"I-product\"\n","]\n","\n","\n","# Define the IOB2 scheme (Inside-Outside-Beginning)\n","IOB2 = True\n","\n","def compute_metrics_extended(eval_preds):\n","    logits, labels = eval_preds\n","    predictions = np.argmax(logits, axis=-1)\n","\n","    # Convert label and prediction indices to label names\n","    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n","    pred_labels = [[label_names[p] for p, l in zip(prediction, label) if l != -100] for prediction, label in zip(predictions, labels)]\n","\n","    # Compute metrics using classification_report from seqeval\n","    report = classification_report(true_labels, pred_labels, scheme=IOB2, output_dict=True)\n","\n","    # Initialize variables for micro metrics\n","    tp, fp, fn = 0, 0, 0\n","\n","    # Initialize lists for macro metrics\n","    macro_precision_list = []\n","    macro_recall_list = []\n","    macro_f1_list = []\n","\n","    # Create a dictionary to hold metrics for each entity type\n","    entity_metrics = {}\n","\n","    for entity_type in label_names:\n","        if entity_type != 'O':\n","            entity_type_without_prefix = entity_type[2:]  # Remove the 'B-' or 'I-' prefix\n","\n","            if entity_type_without_prefix not in entity_metrics:\n","                entity_metrics[entity_type_without_prefix] = {}\n","\n","            # Extract metrics for B-label, I-label, and full entities\n","            for label_suffix in [\"\", \"I\"]:\n","                label = entity_type[:2] + label_suffix + entity_type[2:]\n","                if label in report:\n","                    entity_metrics[entity_type_without_prefix][\"precision_\" + label_suffix] = report[label][\"precision\"]\n","                    entity_metrics[entity_type_without_prefix][\"recall_\" + label_suffix] = report[label][\"recall\"]\n","                    entity_metrics[entity_type_without_prefix][\"f1-score_\" + label_suffix] = report[label][\"f1-score\"]\n","                else:\n","                    entity_metrics[entity_type_without_prefix][\"precision_\" + label_suffix] = 0\n","                    entity_metrics[entity_type_without_prefix][\"recall_\" + label_suffix] = 0\n","                    entity_metrics[entity_type_without_prefix][\"f1-score_\" + label_suffix] = 0\n","\n","                # Update tp, fp, fn based on the evaluation results for this entity type\n","                if label in report:\n","                    tp += report[label][\"support\"]\n","                    fp += report[label][\"false positives\"]\n","                    fn += report[label][\"false negatives\"]\n","\n","    # Calculate micro-average metrics if there are any true positives\n","    if tp > 0:\n","        micro_precision = tp / (tp + fp)\n","        micro_recall = tp / (tp + fn)\n","        micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall)\n","    else:\n","        micro_precision = 0\n","        micro_recall = 0\n","        micro_f1 = 0\n","\n","    # Calculate macro-average metrics\n","    for entity_type in entity_metrics:\n","        precision_key = \"precision\" if \"precision\" in entity_metrics[entity_type] else \"precision_\"\n","        recall_key = \"recall\" if \"recall\" in entity_metrics[entity_type] else \"recall_\"\n","        f1_key = \"f1-score\" if \"f1-score\" in entity_metrics[entity_type] else \"f1-score_\"\n","\n","        macro_precision_list.append(entity_metrics[entity_type][precision_key])\n","        macro_recall_list.append(entity_metrics[entity_type][recall_key])\n","        macro_f1_list.append(entity_metrics[entity_type][f1_key])\n","\n","    macro_precision = np.mean(macro_precision_list)\n","    macro_recall = np.mean(macro_recall_list)\n","    macro_f1 = np.mean(macro_f1_list)\n","\n","    return {\n","        \"classification_report\": report,\n","        \"micro_precision\": micro_precision,\n","        \"micro_recall\": micro_recall,\n","        \"micro_f1\": micro_f1,\n","        \"macro_precision\": macro_precision,\n","        \"macro_recall\": macro_recall,\n","        \"macro_f1\": macro_f1,\n","        \"entity_metrics\": entity_metrics,\n","    }\n"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6f0a95abeff547c79f1505882830e511","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2547 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e099585d8b174a5da21384a56812cd83","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/161 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"{'corporation': {'precision': 0.7346153846153847, 'recall': 0.3345008756567426, 'f1-score': 0.45968712394705186, 'support': 571}, 'creative-work': {'precision': 0.28160919540229884, 'recall': 0.21120689655172414, 'f1-score': 0.24137931034482757, 'support': 232}, 'group': {'precision': 0.24647887323943662, 'recall': 0.15151515151515152, 'f1-score': 0.18766756032171583, 'support': 231}, 'location': {'precision': 0.6875, 'recall': 0.29333333333333333, 'f1-score': 0.411214953271028, 'support': 150}, 'person': {'precision': 0.5773195876288659, 'recall': 0.24034334763948498, 'f1-score': 0.33939393939393936, 'support': 233}, 'product': {'precision': 0.2222222222222222, 'recall': 0.12598425196850394, 'f1-score': 0.16080402010050251, 'support': 127}, 'micro avg': {'precision': 0.48331273176761436, 'recall': 0.25323834196891193, 'f1-score': 0.3323416914577136, 'support': 1544}, 'macro avg': {'precision': 0.45829087718470135, 'recall': 0.22614730944415673, 'f1-score': 0.30002448456317754, 'support': 1544}, 'weighted avg': {'precision': 0.5230557149007614, 'recall': 0.25323834196891193, 'f1-score': 0.33874073551184514, 'support': 1544}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]}],"source":["args_combination_1 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-1\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=1e-4,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=4,\n","    push_to_hub=True,\n",")\n","\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_1,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics_extended,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"403daec941ea4f8d81da5a15f3f6cded","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/849 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c5757e1cf99c4740a535b4e6682d375a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.20652173913043478, 'recall': 0.25675675675675674, 'f1-score': 0.2289156626506024, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.20652173913043478, 'recall': 0.016281062553556127, 'f1-score': 0.030182684670373314, 'support': 1167}, 'macro avg': {'precision': 0.034420289855072464, 'recall': 0.04279279279279279, 'f1-score': 0.038152610441767064, 'support': 1167}, 'weighted avg': {'precision': 0.013095637271338624, 'recall': 0.016281062553556127, 'f1-score': 0.014515646132086182, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"30d6618eac6945a0b2307120e47d3ebd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.2361111111111111, 'recall': 0.22972972972972974, 'f1-score': 0.2328767123287671, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.2361111111111111, 'recall': 0.01456726649528706, 'f1-score': 0.02744148506860371, 'support': 1167}, 'macro avg': {'precision': 0.03935185185185185, 'recall': 0.03828828828828829, 'f1-score': 0.03881278538812785, 'support': 1167}, 'weighted avg': {'precision': 0.014971912786822812, 'recall': 0.01456726649528706, 'f1-score': 0.014766818091112912, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"078537730b2e4d75ae1e91ececefbc7d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.21176470588235294, 'recall': 0.24324324324324326, 'f1-score': 0.22641509433962265, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.21176470588235294, 'recall': 0.015424164524421594, 'f1-score': 0.02875399361022364, 'support': 1167}, 'macro avg': {'precision': 0.03529411764705882, 'recall': 0.04054054054054054, 'f1-score': 0.03773584905660377, 'support': 1167}, 'weighted avg': {'precision': 0.013428096174202328, 'recall': 0.015424164524421594, 'f1-score': 0.014357083959838968, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4c47bc0d57c43bbb79d7082f485f7b8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/161 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 571}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 232}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 231}, 'location': {'precision': 0.21568627450980393, 'recall': 0.22, 'f1-score': 0.21782178217821785, 'support': 150}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 233}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 127}, 'micro avg': {'precision': 0.21568627450980393, 'recall': 0.021373056994818652, 'f1-score': 0.03889216263995286, 'support': 1544}, 'macro avg': {'precision': 0.03594771241830066, 'recall': 0.03666666666666667, 'f1-score': 0.036303630363036306, 'support': 1544}, 'weighted avg': {'precision': 0.020953977445900638, 'recall': 0.021373056994818652, 'f1-score': 0.021161442569127383, 'support': 1544}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]}],"source":["args_combination_2 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-2\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=1e-4,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=12,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_2,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics_extended,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"28d040e8fd4e4f6e80375e08e92e11b4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2547 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af64e10d4ced44f6bf04c632b38b0176","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.17475728155339806, 'recall': 0.24324324324324326, 'f1-score': 0.20338983050847462, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.17475728155339806, 'recall': 0.015424164524421594, 'f1-score': 0.028346456692913382, 'support': 1167}, 'macro avg': {'precision': 0.02912621359223301, 'recall': 0.04054054054054054, 'f1-score': 0.03389830508474577, 'support': 1167}, 'weighted avg': {'precision': 0.011081438590361144, 'recall': 0.015424164524421594, 'f1-score': 0.012897041523245176, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"221505af078d4619b8067c122ffc71ec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.14516129032258066, 'recall': 0.24324324324324326, 'f1-score': 0.18181818181818182, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.14516129032258066, 'recall': 0.015424164524421594, 'f1-score': 0.0278853601859024, 'support': 1167}, 'macro avg': {'precision': 0.024193548387096777, 'recall': 0.04054054054054054, 'f1-score': 0.030303030303030304, 'support': 1167}, 'weighted avg': {'precision': 0.009204743345219339, 'recall': 0.015424164524421594, 'f1-score': 0.01152917348290099, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9d3bb3870fc4f978eb1fe8de7630076","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.20930232558139536, 'recall': 0.24324324324324326, 'f1-score': 0.225, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.20930232558139536, 'recall': 0.015424164524421594, 'f1-score': 0.028731045490822026, 'support': 1167}, 'macro avg': {'precision': 0.03488372093023256, 'recall': 0.04054054054054054, 'f1-score': 0.0375, 'support': 1167}, 'weighted avg': {'precision': 0.01327195552101393, 'recall': 0.015424164524421594, 'f1-score': 0.014267352185089977, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ae7f125238454c95ad0bf736295883a9","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/161 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 571}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 232}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 231}, 'location': {'precision': 0.21019108280254778, 'recall': 0.22, 'f1-score': 0.21498371335504884, 'support': 150}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 233}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 127}, 'micro avg': {'precision': 0.21019108280254778, 'recall': 0.021373056994818652, 'f1-score': 0.03880070546737214, 'support': 1544}, 'macro avg': {'precision': 0.03503184713375796, 'recall': 0.03666666666666667, 'f1-score': 0.03583061889250814, 'support': 1544}, 'weighted avg': {'precision': 0.02042011814791591, 'recall': 0.021373056994818652, 'f1-score': 0.020885723447705524, 'support': 1544}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]}],"source":["args_combination_3 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-3\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=4,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_3,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics_extended,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc9fae63dc104bd4b82bb40985709731","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/849 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd2622531a5942dbab0a50eaf472eb4f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.19387755102040816, 'recall': 0.25675675675675674, 'f1-score': 0.2209302325581395, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.19387755102040816, 'recall': 0.016281062553556127, 'f1-score': 0.0300395256916996, 'support': 1167}, 'macro avg': {'precision': 0.03231292517006803, 'recall': 0.04279279279279279, 'f1-score': 0.036821705426356585, 'support': 1167}, 'weighted avg': {'precision': 0.012293863560848503, 'recall': 0.016281062553556127, 'f1-score': 0.01400928638329248, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd1dc9f3cabf41eb883c9d8ac6aa0bbf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.20689655172413793, 'recall': 0.24324324324324326, 'f1-score': 0.2236024844720497, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.20689655172413793, 'recall': 0.015424164524421594, 'f1-score': 0.028708133971291863, 'support': 1167}, 'macro avg': {'precision': 0.034482758620689655, 'recall': 0.04054054054054054, 'f1-score': 0.037267080745341616, 'support': 1167}, 'weighted avg': {'precision': 0.013119404308128711, 'recall': 0.015424164524421594, 'f1-score': 0.014178735090772648, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3fc02df0fbb84e59a6d32ad5cf32ccc3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.23684210526315788, 'recall': 0.24324324324324326, 'f1-score': 0.23999999999999996, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.23684210526315788, 'recall': 0.015424164524421594, 'f1-score': 0.028962188254223652, 'support': 1167}, 'macro avg': {'precision': 0.039473684210526314, 'recall': 0.04054054054054054, 'f1-score': 0.039999999999999994, 'support': 1167}, 'weighted avg': {'precision': 0.015018265457989448, 'recall': 0.015424164524421594, 'f1-score': 0.015218508997429304, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f697bf687b341aea0049ac491a232c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/161 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 571}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 232}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 231}, 'location': {'precision': 0.2158273381294964, 'recall': 0.2, 'f1-score': 0.20761245674740486, 'support': 150}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 233}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 127}, 'micro avg': {'precision': 0.2158273381294964, 'recall': 0.019430051813471502, 'f1-score': 0.035650623885918005, 'support': 1544}, 'macro avg': {'precision': 0.03597122302158273, 'recall': 0.03333333333333333, 'f1-score': 0.03460207612456748, 'support': 1544}, 'weighted avg': {'precision': 0.020967681813098743, 'recall': 0.019430051813471502, 'f1-score': 0.020169603958620937, 'support': 1544}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]}],"source":["args_combination_4 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-4\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=12,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_4,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics_extended,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0846f1bd433d400fa08dba9b726056a4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2547 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"55a7cace78424578806a01880e339baf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.2903225806451613, 'recall': 0.24324324324324326, 'f1-score': 0.2647058823529412, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.2903225806451613, 'recall': 0.015424164524421594, 'f1-score': 0.02929210740439382, 'support': 1167}, 'macro avg': {'precision': 0.048387096774193554, 'recall': 0.04054054054054054, 'f1-score': 0.04411764705882353, 'support': 1167}, 'weighted avg': {'precision': 0.018409486690438678, 'recall': 0.015424164524421594, 'f1-score': 0.016785120217752914, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66dbe1159bd74677b5d4f487037dadd8","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.17307692307692307, 'recall': 0.24324324324324326, 'f1-score': 0.20224719101123595, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.17307692307692307, 'recall': 0.015424164524421594, 'f1-score': 0.028324154209284032, 'support': 1167}, 'macro avg': {'precision': 0.028846153846153844, 'recall': 0.04054054054054054, 'f1-score': 0.033707865168539325, 'support': 1167}, 'weighted avg': {'precision': 0.010974886296223056, 'recall': 0.015424164524421594, 'f1-score': 0.01282458623378874, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f75828521eff46aa855f6beb2505e58d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.15384615384615385, 'recall': 0.24324324324324326, 'f1-score': 0.18848167539267016, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.15384615384615385, 'recall': 0.015424164524421594, 'f1-score': 0.028037383177570097, 'support': 1167}, 'macro avg': {'precision': 0.025641025641025644, 'recall': 0.04054054054054054, 'f1-score': 0.031413612565445025, 'support': 1167}, 'weighted avg': {'precision': 0.009755454485531606, 'recall': 0.015424164524421594, 'f1-score': 0.011951708636724586, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"330e495a14cb40b7bfb9df1d11cab8ff","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/161 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 571}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 232}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 231}, 'location': {'precision': 0.20540540540540542, 'recall': 0.25333333333333335, 'f1-score': 0.22686567164179106, 'support': 150}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 233}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 127}, 'micro avg': {'precision': 0.20540540540540542, 'recall': 0.02461139896373057, 'f1-score': 0.04395604395604396, 'support': 1544}, 'macro avg': {'precision': 0.03423423423423424, 'recall': 0.042222222222222223, 'f1-score': 0.037810945273631845, 'support': 1544}, 'weighted avg': {'precision': 0.019955188348970733, 'recall': 0.02461139896373057, 'f1-score': 0.02204005877349006, 'support': 1544}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]}],"source":["args_combination_5 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-5\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=4,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_5,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics_extended,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e9247fc10254a078c0473ae83399c2c","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/849 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c55ac4e47a9499e80de85b5af96e1fb","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.15789473684210525, 'recall': 0.24324324324324326, 'f1-score': 0.19148936170212766, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.15789473684210525, 'recall': 0.015424164524421594, 'f1-score': 0.028103044496487123, 'support': 1167}, 'macro avg': {'precision': 0.02631578947368421, 'recall': 0.04054054054054054, 'f1-score': 0.031914893617021274, 'support': 1167}, 'weighted avg': {'precision': 0.010012176971992965, 'recall': 0.015424164524421594, 'f1-score': 0.012142427391565935, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cafeedd589e149e5af4a9e03765996bc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.12337662337662338, 'recall': 0.25675675675675674, 'f1-score': 0.16666666666666666, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.12337662337662338, 'recall': 0.016281062553556127, 'f1-score': 0.028766086298258896, 'support': 1167}, 'macro avg': {'precision': 0.020562770562770564, 'recall': 0.04279279279279279, 'f1-score': 0.027777777777777776, 'support': 1167}, 'weighted avg': {'precision': 0.007823367720539957, 'recall': 0.016281062553556127, 'f1-score': 0.010568409025992572, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f09a9b7373c4ae3915dedfd48319f39","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.13043478260869565, 'recall': 0.24324324324324326, 'f1-score': 0.16981132075471697, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.13043478260869565, 'recall': 0.015424164524421594, 'f1-score': 0.027586206896551717, 'support': 1167}, 'macro avg': {'precision': 0.021739130434782608, 'recall': 0.04054054054054054, 'f1-score': 0.028301886792452827, 'support': 1167}, 'weighted avg': {'precision': 0.00827092880295071, 'recall': 0.015424164524421594, 'f1-score': 0.010767812969879225, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"48378030f28a44b0a72c0562f6c6c49a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/161 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 571}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 232}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 231}, 'location': {'precision': 0.17757009345794392, 'recall': 0.25333333333333335, 'f1-score': 0.2087912087912088, 'support': 150}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 233}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 127}, 'micro avg': {'precision': 0.17757009345794392, 'recall': 0.02461139896373057, 'f1-score': 0.04323094425483504, 'support': 1544}, 'macro avg': {'precision': 0.029595015576323987, 'recall': 0.042222222222222223, 'f1-score': 0.0347985347985348, 'support': 1544}, 'weighted avg': {'precision': 0.017250980582054137, 'recall': 0.02461139896373057, 'f1-score': 0.020284120025052668, 'support': 1544}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]}],"source":["args_combination_6 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-6\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=12,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_6,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics_extended,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc7d808f50d94032aaab1995b7f112c0","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/849 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"63e64891dd2c4d34808b235f5ebc3f70","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.20454545454545456, 'recall': 0.24324324324324326, 'f1-score': 0.22222222222222227, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.20454545454545456, 'recall': 0.015424164524421594, 'f1-score': 0.028685258964143423, 'support': 1167}, 'macro avg': {'precision': 0.034090909090909095, 'recall': 0.04054054054054054, 'f1-score': 0.03703703703703704, 'support': 1167}, 'weighted avg': {'precision': 0.012970320168263614, 'recall': 0.015424164524421594, 'f1-score': 0.014091212034656766, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e3741948a640443f9a019a8871a83162","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.17307692307692307, 'recall': 0.24324324324324326, 'f1-score': 0.20224719101123595, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.17307692307692307, 'recall': 0.015424164524421594, 'f1-score': 0.028324154209284032, 'support': 1167}, 'macro avg': {'precision': 0.028846153846153844, 'recall': 0.04054054054054054, 'f1-score': 0.033707865168539325, 'support': 1167}, 'weighted avg': {'precision': 0.010974886296223056, 'recall': 0.015424164524421594, 'f1-score': 0.01282458623378874, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"172e2ca2d8bb4e1fbe9ba0482c4fbfad","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.1782178217821782, 'recall': 0.24324324324324326, 'f1-score': 0.2057142857142857, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.1782178217821782, 'recall': 0.015424164524421594, 'f1-score': 0.028391167192429023, 'support': 1167}, 'macro avg': {'precision': 0.0297029702970297, 'recall': 0.04054054054054054, 'f1-score': 0.03428571428571429, 'support': 1167}, 'weighted avg': {'precision': 0.011300873017893048, 'recall': 0.015424164524421594, 'f1-score': 0.013044436283510834, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d9d7546fda684fac8664c458f4da0a22","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/161 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 571}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 232}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 231}, 'location': {'precision': 0.20454545454545456, 'recall': 0.24, 'f1-score': 0.22085889570552147, 'support': 150}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 233}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 127}, 'micro avg': {'precision': 0.20454545454545456, 'recall': 0.023316062176165803, 'f1-score': 0.04186046511627907, 'support': 1544}, 'macro avg': {'precision': 0.034090909090909095, 'recall': 0.04, 'f1-score': 0.03680981595092025, 'support': 1544}, 'weighted avg': {'precision': 0.01987164390014131, 'recall': 0.023316062176165803, 'f1-score': 0.021456498935121904, 'support': 1544}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]}],"source":["args_combination_7 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-7\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=1e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=4,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_6,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics_extended,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"265122031f5f4f1e866bc0db810d8315","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/849 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fcacbad6a04c49cf92b355610d53310e","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.09895833333333333, 'recall': 0.25675675675675674, 'f1-score': 0.14285714285714285, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.09895833333333333, 'recall': 0.016281062553556127, 'f1-score': 0.027961736571008092, 'support': 1167}, 'macro avg': {'precision': 0.016493055555555556, 'recall': 0.04279279279279279, 'f1-score': 0.023809523809523808, 'support': 1167}, 'weighted avg': {'precision': 0.00627499285918309, 'recall': 0.016281062553556127, 'f1-score': 0.009058636307993634, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f44828cf541048d6b78e4e2312c4e228","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.11920529801324503, 'recall': 0.24324324324324326, 'f1-score': 0.16, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.11920529801324503, 'recall': 0.015424164524421594, 'f1-score': 0.027314112291350535, 'support': 1167}, 'macro avg': {'precision': 0.019867549668874173, 'recall': 0.04054054054054054, 'f1-score': 0.02666666666666667, 'support': 1167}, 'weighted avg': {'precision': 0.00755886208481588, 'recall': 0.015424164524421594, 'f1-score': 0.01014567266495287, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b8d24453366145b1921016ec0f4f2071","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/127 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 575}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 141}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 72}, 'location': {'precision': 0.10465116279069768, 'recall': 0.24324324324324326, 'f1-score': 0.14634146341463414, 'support': 74}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 213}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 92}, 'micro avg': {'precision': 0.10465116279069768, 'recall': 0.015424164524421594, 'f1-score': 0.0268857356235997, 'support': 1167}, 'macro avg': {'precision': 0.01744186046511628, 'recall': 0.04054054054054054, 'f1-score': 0.024390243902439022, 'support': 1167}, 'weighted avg': {'precision': 0.006635977760506965, 'recall': 0.015424164524421594, 'f1-score': 0.009279578656969089, 'support': 1167}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"99eb607538c04108b681bc85fa6da5a6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/161 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/Users/vanbuncha/anaconda3/envs/tm_as2/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Trainer is attempting to log a value of \"{'corporation': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 571}, 'creative-work': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 232}, 'group': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 231}, 'location': {'precision': 0.15639810426540285, 'recall': 0.22, 'f1-score': 0.18282548476454294, 'support': 150}, 'person': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 233}, 'product': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 127}, 'micro avg': {'precision': 0.15639810426540285, 'recall': 0.021373056994818652, 'f1-score': 0.037606837606837605, 'support': 1544}, 'macro avg': {'precision': 0.026066350710900476, 'recall': 0.03666666666666667, 'f1-score': 0.030470914127423823, 'support': 1544}, 'weighted avg': {'precision': 0.015194116347027479, 'recall': 0.021373056994818652, 'f1-score': 0.017761543208990573, 'support': 1544}}\" of type <class 'dict'> for key \"eval/classification_report\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Trainer is attempting to log a value of \"{'location': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'group': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'corporation': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'person': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'creative-work': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}, 'product': {'precision_': 0, 'recall_': 0, 'f1-score_': 0, 'precision_I': 0, 'recall_I': 0, 'f1-score_I': 0}}\" of type <class 'dict'> for key \"eval/entity_metrics\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]}],"source":["args_combination_8 = TrainingArguments(\n","    \"bert-finetuned-ner-combination-8\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    learning_rate=1e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    per_device_train_batch_size=12,\n","    push_to_hub=True,\n",")\n","trainer = Trainer(\n","    model=model,\n","    args=args_combination_8,  \n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"test\"],  \n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics_extended,\n","    tokenizer=tokenizer,\n",")\n","\n","trainer.train()\n","\n","# After training, evaluate the model on the test set\n","test_results = trainer.evaluate(tokenized_datasets[\"test\"])\n","\n","# Print the test results\n","print(\"Test Results:\")\n","print(test_results)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"021f4c6999d1477688b3061e15d19336":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"025a65adc4d44471a940bb9438f94a01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"08efea0cab4e4ee7aa39cbbaf9486df2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"121c674a665b4948b2b903e653737450":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a22a4582dd464aa9869748436347358f","placeholder":"​","style":"IPY_MODEL_021f4c6999d1477688b3061e15d19336","value":"Login successful"}},"12d46c6c85c04096a78d782c0a93723b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"13c8168776c34da4858c6d678475e010":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"18f0209dfd2d4f71a61cff974aae5da5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"200a35f4004544f8a2f384feae489636":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20336a9b683643348df644c68fc123ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a20e59edf8764338bcb9bd59cb60ad3f","placeholder":"​","style":"IPY_MODEL_ef06580993bb42779ef7028dfa33cd67","value":"Map: 100%"}},"2087c04b93f3460583185651885eac95":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20df35f6fce148b08032e1674e4653ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"210181f7497a47c0a539ff0900bc40a7":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"2119f9c3f36e490d8bcdac326ef46e81":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21af6a41e3734646a874bdad2ca5a158":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f29d32431064fa2abaeba808c6fbc7e","placeholder":"​","style":"IPY_MODEL_dbed1899815646279af9ea1669431571","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"29e200b20e074ad1b546742bfb1bbece":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d72399f9abf24905ad6236456099eb02","placeholder":"​","style":"IPY_MODEL_eaa673163fbd42128d480190bc7c53da","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"2edbf105a692434eab996204affb1f87":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"317ad3998a1746eb9523b018f41acff6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_587d3e7d8ec14e9b85945916ccbe0829","placeholder":"​","style":"IPY_MODEL_8ef27ef18f3745c8a4b472b79c279cab","value":"Your token has been saved in your configured git credential helpers (store)."}},"33ec04869b82415f96c94198e95c361a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a9e3461c0fc416986f42753e242e28d","placeholder":"​","style":"IPY_MODEL_b33ee0b53a264d198a7f6bf64fcd14e8","value":"Token is valid (permission: write)."}},"3beb5812aba344caac21533a424534a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8bed15f7fe1457b85cb56f0205cc6ce","placeholder":"​","style":"IPY_MODEL_a3d95dd667a748169088614179227117","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"42a42f73b163476dbd789ee0c679a51b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4318d59a725842dd8e7d71df077a129c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_686b84fa6d244287a714d686a6c965dc","placeholder":"​","style":"IPY_MODEL_e570a9ca0ba541b38adc118c995bb979","value":" 3394/3394 [00:02&lt;00:00, 1964.62 examples/s]"}},"4a1aaabfc8314220bfe963384eb126e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4ab3c5e6542441c0849ce5288d10dd94":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a6099f4f07824d7aa99b0cbbba4c2fcd","IPY_MODEL_6b814cadc489493aae69d0fa3ec6551f","IPY_MODEL_af271bad93c243c7b8d9e812e402ebec"],"layout":"IPY_MODEL_5eb959b3607845cf8f0bcba2ad11a7ab"}},"4ba999c38b9e4343adb3ab300766eb5f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d96f407a9334e12aaf320c241d39f37":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f3f9bad30224826a6a620bb391312d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5228b938a5af4ede8c9b5a8c48f5805e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"52c0866d7a664e25afdc2f87648fc17b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5406b0025a7a49408d6a179d19fb38dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5653ac6638d64703b148f2683afab99f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b99690a237c340359256bcd521a9ccac","placeholder":"​","style":"IPY_MODEL_200a35f4004544f8a2f384feae489636","value":"Your token has been saved in your configured git credential helpers (store)."}},"587d3e7d8ec14e9b85945916ccbe0829":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ae3da8b1af94657a5149b0f046accda":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_93d00b2635b3450a84db556c4a175e89","IPY_MODEL_5653ac6638d64703b148f2683afab99f","IPY_MODEL_dcb9947e55d8480a8b800937731fb384","IPY_MODEL_121c674a665b4948b2b903e653737450"],"layout":"IPY_MODEL_9c4f0084cc6d4ae788ef83cc72ce323c"}},"5eb959b3607845cf8f0bcba2ad11a7ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f29d32431064fa2abaeba808c6fbc7e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66a887bd9fee454dbe5adb6959471a49":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"686b84fa6d244287a714d686a6c965dc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ac6ee23163c43b59dc5f13373ea397a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b814cadc489493aae69d0fa3ec6551f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cfc0cc7c3d44de08fcf82934b17a66e","max":1287,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c60019140b24a21aaaa6564b030b93d","value":1287}},"6c03912dfa7247418ae4f1507d25f030":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6c755fb412624b809d1f2de97fc591b9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c9b49cbe7b941cba170034d8f3f24ab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7070de3dd1604851b46bb1e6fa93f89a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c2175d0b13a44ea9877928297a2886b","IPY_MODEL_fccd3e0011d340048a2055b673cf2f81","IPY_MODEL_dcfde0e4214344c5a341dfc72295cf05"],"layout":"IPY_MODEL_a70acbe6f5c8405c9843b09d1edf3970"}},"710d2fdc396a4788b8e68fedb8d8bd06":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_42a42f73b163476dbd789ee0c679a51b","placeholder":"​","style":"IPY_MODEL_18f0209dfd2d4f71a61cff974aae5da5","value":""}},"713c6e2c9c8b44cb8b3a4c1ac2c2e615":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74d33f3a596a41c2b0b1fde6a9a6afd2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79af72e64fcb4c34bba1d9396e392195":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86d5d1ee288941818bb77eb4d66d7d67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab7d5f51566740d08351e5beff9f3534","placeholder":"​","style":"IPY_MODEL_713c6e2c9c8b44cb8b3a4c1ac2c2e615","value":"Connecting..."}},"8a9e3461c0fc416986f42753e242e28d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c60019140b24a21aaaa6564b030b93d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8ef27ef18f3745c8a4b472b79c279cab":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93d00b2635b3450a84db556c4a175e89":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d612714f76b54d128e96b41ba56dce80","placeholder":"​","style":"IPY_MODEL_5228b938a5af4ede8c9b5a8c48f5805e","value":"Token is valid (permission: read)."}},"9c2175d0b13a44ea9877928297a2886b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2119f9c3f36e490d8bcdac326ef46e81","placeholder":"​","style":"IPY_MODEL_c5cd5acf42334b66b917eedb1e40635b","value":"Map: 100%"}},"9c4f0084cc6d4ae788ef83cc72ce323c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"9cfc0cc7c3d44de08fcf82934b17a66e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fa399ff818b4b8d91c1ae1b566990b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_b285da0dbc044b70a389be7456b24fbc","style":"IPY_MODEL_12d46c6c85c04096a78d782c0a93723b","value":true}},"a20e59edf8764338bcb9bd59cb60ad3f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a22a4582dd464aa9869748436347358f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3b9fc0503ab428bac43634b7cb6e3ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74d33f3a596a41c2b0b1fde6a9a6afd2","placeholder":"​","style":"IPY_MODEL_025a65adc4d44471a940bb9438f94a01","value":"Login successful"}},"a3d95dd667a748169088614179227117":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4b0e51d168e4c62b6daa9671eca21b2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6099f4f07824d7aa99b0cbbba4c2fcd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b198a9a47de8437d84e793f6ad9f19a5","placeholder":"​","style":"IPY_MODEL_4a1aaabfc8314220bfe963384eb126e5","value":"Map: 100%"}},"a70acbe6f5c8405c9843b09d1edf3970":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ab7d5f51566740d08351e5beff9f3534":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abe09dad02ac417da4191eaac66f8a86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d96f407a9334e12aaf320c241d39f37","placeholder":"​","style":"IPY_MODEL_4ba999c38b9e4343adb3ab300766eb5f","value":"Your token has been saved to /root/.cache/huggingface/token"}},"af271bad93c243c7b8d9e812e402ebec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4f3f9bad30224826a6a620bb391312d9","placeholder":"​","style":"IPY_MODEL_66a887bd9fee454dbe5adb6959471a49","value":" 1287/1287 [00:00&lt;00:00, 2997.97 examples/s]"}},"af42b8e33657455c9fe793d3c53a993b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"VBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_33ec04869b82415f96c94198e95c361a","IPY_MODEL_317ad3998a1746eb9523b018f41acff6","IPY_MODEL_abe09dad02ac417da4191eaac66f8a86","IPY_MODEL_a3b9fc0503ab428bac43634b7cb6e3ec"],"layout":"IPY_MODEL_210181f7497a47c0a539ff0900bc40a7"}},"b198a9a47de8437d84e793f6ad9f19a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b22e69dc22f542a2a022f5c1f648607b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b285da0dbc044b70a389be7456b24fbc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b2e2df2f59824e838a04468bdc567a68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b33ee0b53a264d198a7f6bf64fcd14e8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b49a110f519c4506807410efa183c864":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52c0866d7a664e25afdc2f87648fc17b","placeholder":"​","style":"IPY_MODEL_5406b0025a7a49408d6a179d19fb38dc","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"b75715e40b904e048c0a4314eadd41eb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20df35f6fce148b08032e1674e4653ef","max":3394,"min":0,"orientation":"horizontal","style":"IPY_MODEL_08efea0cab4e4ee7aa39cbbaf9486df2","value":3394}},"b8bed15f7fe1457b85cb56f0205cc6ce":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b99690a237c340359256bcd521a9ccac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba05ea5c28ab4d898dc44c28939798bc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c106d63563c84fcf91c07f6a6f3b3199":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_6ac6ee23163c43b59dc5f13373ea397a","style":"IPY_MODEL_13c8168776c34da4858c6d678475e010","tooltip":""}},"c5cd5acf42334b66b917eedb1e40635b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca1f51909bd54526a84e9b4814a12f71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"PasswordModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_dba2514b49304ff1b0c39390a836f5f0","placeholder":"​","style":"IPY_MODEL_2087c04b93f3460583185651885eac95","value":""}},"cae4590e5d564254957207fdfae071a2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cbec063e98d04d33822df13c386021e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ButtonModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_6c755fb412624b809d1f2de97fc591b9","style":"IPY_MODEL_2edbf105a692434eab996204affb1f87","tooltip":""}},"cd865b8b967b4fa68ae67b825afa9978":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_20336a9b683643348df644c68fc123ac","IPY_MODEL_b75715e40b904e048c0a4314eadd41eb","IPY_MODEL_4318d59a725842dd8e7d71df077a129c"],"layout":"IPY_MODEL_a4b0e51d168e4c62b6daa9671eca21b2"}},"d612714f76b54d128e96b41ba56dce80":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d62e1749d1a44eb6825ec3f46b3651f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d72399f9abf24905ad6236456099eb02":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dba2514b49304ff1b0c39390a836f5f0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dbed1899815646279af9ea1669431571":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dcb9947e55d8480a8b800937731fb384":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d62e1749d1a44eb6825ec3f46b3651f9","placeholder":"​","style":"IPY_MODEL_b22e69dc22f542a2a022f5c1f648607b","value":"Your token has been saved to /root/.cache/huggingface/token"}},"dcfde0e4214344c5a341dfc72295cf05":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e3bc0d3e70704170bcd98f29a0d306bc","placeholder":"​","style":"IPY_MODEL_ba05ea5c28ab4d898dc44c28939798bc","value":" 1009/1009 [00:00&lt;00:00, 3616.09 examples/s]"}},"deabb55f665d4cee9234564c90a7911f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"LabelModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fb248e41a08d4c5f94a207ed9c2eb8d5","placeholder":"​","style":"IPY_MODEL_79af72e64fcb4c34bba1d9396e392195","value":"Connecting..."}},"e3bc0d3e70704170bcd98f29a0d306bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e570a9ca0ba541b38adc118c995bb979":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eaa673163fbd42128d480190bc7c53da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef06580993bb42779ef7028dfa33cd67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb248e41a08d4c5f94a207ed9c2eb8d5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbe726a3c52240d096d2f3dd6f164333":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"CheckboxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_b2e2df2f59824e838a04468bdc567a68","style":"IPY_MODEL_6c9b49cbe7b941cba170034d8f3f24ab","value":true}},"fccd3e0011d340048a2055b673cf2f81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cae4590e5d564254957207fdfae071a2","max":1009,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c03912dfa7247418ae4f1507d25f030","value":1009}}}}},"nbformat":4,"nbformat_minor":0}
