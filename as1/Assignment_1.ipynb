{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TASK 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -U scikit-learn\n",
    "# ! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11314\n",
      "11314\n",
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "rec.autos\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names\n",
    "print(len(twenty_train.data))\n",
    "print(len(twenty_train.filenames))\n",
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))\n",
    "print(twenty_train.target_names[twenty_train.target[0]])\n",
    "twenty_train.target[:10]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos\n",
      "comp.sys.mac.hardware\n",
      "comp.sys.mac.hardware\n",
      "comp.graphics\n",
      "sci.space\n",
      "talk.politics.guns\n",
      "sci.med\n",
      "comp.sys.ibm.pc.hardware\n",
      "comp.os.ms-windows.misc\n",
      "comp.sys.mac.hardware\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for t in twenty_train.target[:10]:\n",
    "    print(twenty_train.target_names[t])\n",
    "\n",
    "\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27366"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_transformer = TfidfTransformer(use_idf=False).fit(X_train_counts)\n",
    "X_train_tf = tf_transformer.transform(X_train_counts)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 130107)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => rec.autos\n"
     ]
    }
   ],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc, category in zip(docs_new, predicted):\n",
    "    print('%r => %s' % (doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', MultinomialNB()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7738980350504514"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
       "                               tol=None))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vect&#x27;, CountVectorizer()), (&#x27;tfidf&#x27;, TfidfTransformer()),\n",
       "                (&#x27;clf&#x27;,\n",
       "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
       "                               tol=None))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SGDClassifier</label><div class=\"sk-toggleable__content\"><pre>SGDClassifier(alpha=0.001, max_iter=5, random_state=42, tol=None)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf',\n",
       "                 SGDClassifier(alpha=0.001, max_iter=5, random_state=42,\n",
       "                               tol=None))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8248805098247477"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.71      0.72       319\n",
      "           comp.graphics       0.78      0.72      0.75       389\n",
      " comp.os.ms-windows.misc       0.73      0.78      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.74      0.67      0.70       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.84      0.76      0.80       395\n",
      "            misc.forsale       0.84      0.90      0.87       390\n",
      "               rec.autos       0.91      0.90      0.90       396\n",
      "         rec.motorcycles       0.93      0.96      0.95       398\n",
      "      rec.sport.baseball       0.88      0.90      0.89       397\n",
      "        rec.sport.hockey       0.88      0.99      0.93       399\n",
      "               sci.crypt       0.84      0.96      0.90       396\n",
      "         sci.electronics       0.83      0.62      0.71       393\n",
      "                 sci.med       0.87      0.86      0.87       396\n",
      "               sci.space       0.84      0.96      0.90       394\n",
      "  soc.religion.christian       0.76      0.94      0.84       398\n",
      "      talk.politics.guns       0.70      0.92      0.80       364\n",
      "   talk.politics.mideast       0.90      0.93      0.92       376\n",
      "      talk.politics.misc       0.89      0.55      0.68       310\n",
      "      talk.religion.misc       0.85      0.41      0.55       251\n",
      "\n",
      "                accuracy                           0.82      7532\n",
      "               macro avg       0.83      0.81      0.81      7532\n",
      "            weighted avg       0.83      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[226,   0,   0,   1,   0,   2,   1,   0,   1,   3,   0,   2,   1,\n",
       "         11,   5,  44,   2,   9,   1,  10],\n",
       "       [  2, 280,  21,   8,   8,  24,   3,   1,   2,   4,   3,   9,   4,\n",
       "          3,   8,   2,   2,   4,   0,   1],\n",
       "       [  1,  11, 307,  21,  13,  12,   1,   0,   0,   6,   2,   7,   1,\n",
       "          1,   7,   2,   0,   1,   0,   1],\n",
       "       [  3,  10,  27, 264,  26,   3,  12,   4,   4,   2,   1,   4,  22,\n",
       "          2,   4,   0,   1,   1,   1,   1],\n",
       "       [  0,   5,   7,  22, 319,   1,   9,   0,   1,   4,   1,   3,   5,\n",
       "          1,   1,   0,   2,   1,   3,   0],\n",
       "       [  1,  32,  42,   0,   3, 299,   2,   0,   1,   1,   1,   2,   1,\n",
       "          1,   7,   1,   1,   0,   0,   0],\n",
       "       [  0,   2,   1,  13,   4,   0, 350,   7,   1,   1,   2,   1,   3,\n",
       "          2,   2,   0,   1,   0,   0,   0],\n",
       "       [  1,   1,   1,   2,   1,   0,  10, 355,   7,   2,   0,   0,  10,\n",
       "          0,   2,   0,   3,   0,   1,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   4,   6, 384,   2,   0,   0,   0,\n",
       "          1,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   2,   0,   3,   0,   0, 358,  32,   0,   0,\n",
       "          0,   0,   0,   1,   1,   0,   0],\n",
       "       [  0,   1,   0,   0,   1,   0,   0,   0,   0,   1, 395,   0,   0,\n",
       "          0,   0,   1,   0,   0,   0,   0],\n",
       "       [  0,   1,   3,   0,   1,   0,   2,   3,   0,   2,   0, 380,   0,\n",
       "          1,   0,   0,   2,   0,   1,   0],\n",
       "       [  7,   7,   9,  22,  12,   5,   8,   8,   7,   6,   2,  30, 242,\n",
       "         10,  13,   3,   1,   1,   0,   0],\n",
       "       [  4,   3,   1,   2,   2,   3,   5,   0,   2,   5,   3,   2,   3,\n",
       "        340,   3,   7,   2,   5,   4,   0],\n",
       "       [  0,   3,   0,   0,   1,   0,   1,   0,   0,   0,   1,   1,   0,\n",
       "          4, 380,   2,   0,   0,   1,   0],\n",
       "       [  8,   0,   2,   1,   0,   0,   0,   0,   1,   0,   0,   0,   1,\n",
       "          2,   3, 376,   0,   0,   0,   4],\n",
       "       [  0,   0,   0,   0,   1,   0,   2,   2,   1,   4,   1,   6,   0,\n",
       "          2,   3,   1, 335,   1,   5,   0],\n",
       "       [  8,   1,   0,   0,   0,   4,   0,   1,   0,   4,   3,   2,   0,\n",
       "          0,   1,   0,   1, 351,   0,   0],\n",
       "       [  3,   1,   0,   0,   1,   1,   1,   0,   1,   0,   2,   4,   0,\n",
       "          4,   7,   3, 102,   9, 170,   1],\n",
       "       [ 45,   1,   1,   0,   0,   0,   2,   2,   0,   0,   1,   0,   0,\n",
       "          4,   6,  56,  22,   5,   4, 102]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(twenty_test.target, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = gs_clf.fit(twenty_train.data[:400], twenty_train.target[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'soc.religion.christian'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target_names[gs_clf.predict(['God is love'])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6275"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clf__alpha: 0.001\n",
      "tfidf__use_idf: True\n",
      "vect__ngram_range: (1, 1)\n"
     ]
    }
   ],
   "source": [
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7738980350504514\n",
      "Precision:0.8218781741893993\n",
      "Recall: 0.7738980350504514\n",
      "F1 Score: 0.7684457156894653\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes Classifier + tfidf:\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', MultinomialNB()),\n",
    " ])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "\n",
    "accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "precision = precision_score(twenty_test.target, predicted, average='weighted')\n",
    "recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision:{precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8248805098247477\n",
      "Precision:0.8280380138303584\n",
      "Recall: 0.8248805098247477\n",
      "F1 Score: 0.8190701989313807\n"
     ]
    }
   ],
   "source": [
    "#SGD Classifier + tfidf:\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "\n",
    "accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "precision = precision_score(twenty_test.target, predicted, average='weighted')\n",
    "recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision:{precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8347052575677111\n",
      "Precision:0.8396041441415458\n",
      "Recall: 0.8347052575677111\n",
      "F1 Score: 0.8345147645688246\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier + tfidf:\n",
    "from sklearn import svm\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', svm.SVC(kernel='linear')),\n",
    "])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "\n",
    "accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "precision = precision_score(twenty_test.target, predicted, average='weighted')\n",
    "recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision:{precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7728359001593202\n",
      "Precision:0.7616683207318354\n",
      "Recall: 0.7728359001593202\n",
      "F1 Score: 0.7511127577441177\n"
     ]
    }
   ],
   "source": [
    "#Naive Bias Classifier + count:\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('clf', MultinomialNB()),\n",
    " ])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "\n",
    "accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "precision = precision_score(twenty_test.target, predicted, average='weighted')\n",
    "recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision:{precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7052575677110993\n",
      "Precision:0.78548015927203\n",
      "Recall: 0.7052575677110993\n",
      "F1 Score: 0.6920561650276855\n"
     ]
    }
   ],
   "source": [
    "#Naive Bias Classifier + tf:\n",
    "text_clf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "     ('clf', MultinomialNB()),\n",
    " ])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "\n",
    "accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "precision = precision_score(twenty_test.target, predicted, average='weighted')\n",
    "recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision:{precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7521242697822623\n",
      "Precision:0.7635144469581859\n",
      "Recall: 0.7521242697822623\n",
      "F1 Score: 0.7523939346262882\n"
     ]
    }
   ],
   "source": [
    "#SGD Classifier + count:\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "\n",
    "accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "precision = precision_score(twenty_test.target, predicted, average='weighted')\n",
    "recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision:{precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7697822623473181\n",
      "Precision:0.7785283134394487\n",
      "Recall: 0.7697822623473181\n",
      "F1 Score: 0.762996798158262\n"
     ]
    }
   ],
   "source": [
    "#SGD Classifier + tf:\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "    ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          max_iter=5, tol=None)),\n",
    "])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "\n",
    "accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "precision = precision_score(twenty_test.target, predicted, average='weighted')\n",
    "recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision:{precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7336696760488582\n",
      "Precision:0.7382348816871909\n",
      "Recall: 0.7336696760488582\n",
      "F1 Score: 0.7335972983749119\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier + count:\n",
    "from sklearn import svm\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', svm.SVC(kernel='linear')),\n",
    "])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "\n",
    "accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "precision = precision_score(twenty_test.target, predicted, average='weighted')\n",
    "recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision:{precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7591609134360063\n",
      "Precision:0.7647608383452609\n",
      "Recall: 0.7591609134360063\n",
      "F1 Score: 0.75800939744818\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier + tf:\n",
    "from sklearn import svm\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer(use_idf=False)),\n",
    "    ('clf', svm.SVC(kernel='linear')),\n",
    "])\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "\n",
    "accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "precision = precision_score(twenty_test.target, predicted, average='weighted')\n",
    "recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision:{precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Classifier + tfidf achieves the best accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lowercasing=True</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.839604</td>\n",
       "      <td>0.834515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lowercasing=False</td>\n",
       "      <td>0.829129</td>\n",
       "      <td>0.829129</td>\n",
       "      <td>0.835501</td>\n",
       "      <td>0.829469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Parameter  Accuracy    Recall  Precision  F1 Score\n",
       "0   lowercasing=True  0.834705  0.834705   0.839604  0.834515\n",
       "1  lowercasing=False  0.829129  0.829129   0.835501  0.829469"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowercasing\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "svm_classifier = svm.SVC(kernel='linear')\n",
    "\n",
    "# Define parameter sets\n",
    "parameter_sets = [\n",
    "    ('lowercasing', [True, False])\n",
    "]\n",
    "results = []\n",
    "\n",
    "# Loop through parameter combinations\n",
    "for param_name, param_values in parameter_sets:\n",
    "    for param_value in param_values:\n",
    "        vectorizer = CountVectorizer(lowercase=param_value)\n",
    "        \n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "        text_clf = Pipeline([\n",
    "            ('vect', vectorizer),\n",
    "            ('tfidf', tfidf_transformer),\n",
    "            ('clf', svm_classifier),\n",
    "        ])\n",
    "\n",
    "        text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "        twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "        docs_test = twenty_test.data\n",
    "        predicted = text_clf.predict(docs_test)\n",
    "\n",
    "        # Calculate accuracy, recall, precision, and F1 score\n",
    "        accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "        recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "        precision = precision_score(twenty_test.target, predicted, average='weighted')\n",
    "        f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "        result = {\n",
    "            'Parameter': f\"{param_name}={param_value}\",\n",
    "            'Accuracy': accuracy,\n",
    "            'Recall': recall,\n",
    "            'Precision': precision,\n",
    "            'F1 Score': f1\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stop_words=None</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.839604</td>\n",
       "      <td>0.834515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stop_words=english</td>\n",
       "      <td>0.834971</td>\n",
       "      <td>0.834971</td>\n",
       "      <td>0.840497</td>\n",
       "      <td>0.834988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Parameter  Accuracy    Recall  Precision  F1 Score\n",
       "0     stop_words=None  0.834705  0.834705   0.839604  0.834515\n",
       "1  stop_words=english  0.834971  0.834971   0.840497  0.834988"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stop_words\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "svm_classifier = svm.SVC(kernel='linear')\n",
    "parameter_sets = [\n",
    "    ('stop_words', [None, 'english'])\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop through parameter combinations\n",
    "for param_name, param_values in parameter_sets:\n",
    "    for param_value in param_values:\n",
    "        vectorizer = CountVectorizer(stop_words=param_value)\n",
    "        \n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "        # Create a pipeline\n",
    "        text_clf = Pipeline([\n",
    "            ('vect', vectorizer),\n",
    "            ('tfidf', tfidf_transformer),\n",
    "            ('clf', svm_classifier),\n",
    "        ])\n",
    "\n",
    "        text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "        twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "        docs_test = twenty_test.data\n",
    "        predicted = text_clf.predict(docs_test)\n",
    "\n",
    "        # Calculate accuracy, recall, precision, and F1 score\n",
    "        accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "        recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "        precision = precision_score(twenty_test.target, predicted, average='weighted')\n",
    "        f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "        # Store results in a dictionary\n",
    "        result = {\n",
    "            'Parameter': f\"{param_name}={param_value}\",\n",
    "            'Accuracy': accuracy,\n",
    "            'Recall': recall,\n",
    "            'Precision': precision,\n",
    "            'F1 Score': f1\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s3726266/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/vol/home/s3726266/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>analyzer=word</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.839604</td>\n",
       "      <td>0.834515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>analyzer=char</td>\n",
       "      <td>0.245751</td>\n",
       "      <td>0.245751</td>\n",
       "      <td>0.254562</td>\n",
       "      <td>0.223204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>analyzer=char_wb</td>\n",
       "      <td>0.196362</td>\n",
       "      <td>0.196362</td>\n",
       "      <td>0.203998</td>\n",
       "      <td>0.161199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ngram_range=(1, 1)</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.839604</td>\n",
       "      <td>0.834515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ngram_range=(1, 2)</td>\n",
       "      <td>0.838555</td>\n",
       "      <td>0.838555</td>\n",
       "      <td>0.845291</td>\n",
       "      <td>0.838780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ngram_range=(2, 2)</td>\n",
       "      <td>0.771907</td>\n",
       "      <td>0.771907</td>\n",
       "      <td>0.789605</td>\n",
       "      <td>0.775060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ngram_range=(2, 3)</td>\n",
       "      <td>0.759161</td>\n",
       "      <td>0.759161</td>\n",
       "      <td>0.780599</td>\n",
       "      <td>0.762704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ngram_range=(3, 3)</td>\n",
       "      <td>0.678837</td>\n",
       "      <td>0.678837</td>\n",
       "      <td>0.729252</td>\n",
       "      <td>0.690051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Parameter  Accuracy    Recall  Precision  F1 Score\n",
       "0       analyzer=word  0.834705  0.834705   0.839604  0.834515\n",
       "1       analyzer=char  0.245751  0.245751   0.254562  0.223204\n",
       "2    analyzer=char_wb  0.196362  0.196362   0.203998  0.161199\n",
       "3  ngram_range=(1, 1)  0.834705  0.834705   0.839604  0.834515\n",
       "4  ngram_range=(1, 2)  0.838555  0.838555   0.845291  0.838780\n",
       "5  ngram_range=(2, 2)  0.771907  0.771907   0.789605  0.775060\n",
       "6  ngram_range=(2, 3)  0.759161  0.759161   0.780599  0.762704\n",
       "7  ngram_range=(3, 3)  0.678837  0.678837   0.729252  0.690051"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyzer + ngram_range\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "\n",
    "svm_classifier = svm.SVC(kernel='linear')\n",
    "parameter_sets = [\n",
    "    ('analyzer', ['word', 'char', 'char_wb']),\n",
    "    ('ngram_range', [(1, 1), (1, 2), (2, 2), (2, 3), (3, 3)])\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop through parameter combinations\n",
    "for param_name, param_values in parameter_sets:\n",
    "    for param_value in param_values:\n",
    "        if param_name == 'analyzer':\n",
    "            vectorizer = CountVectorizer(analyzer=param_value)\n",
    "        elif param_name == 'ngram_range':\n",
    "            vectorizer = CountVectorizer(ngram_range=param_value)\n",
    "        \n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "        # Create a pipeline\n",
    "        text_clf = Pipeline([\n",
    "            ('vect', vectorizer),\n",
    "            ('tfidf', tfidf_transformer),\n",
    "            ('clf', svm_classifier),\n",
    "        ])\n",
    "\n",
    "        text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "        twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "        docs_test = twenty_test.data\n",
    "        predicted = text_clf.predict(docs_test)\n",
    "\n",
    "        # Calculate accuracy, recall, precision, and F1 score\n",
    "        accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "        recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "        precision = precision_score(twenty_test.target, predicted, average='weighted', zero_division='warn')\n",
    "        f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "        # Store results in a dictionary\n",
    "        result = {\n",
    "            'Parameter': f\"{param_name}={param_value}\",\n",
    "            'Accuracy': accuracy,\n",
    "            'Recall': recall,\n",
    "            'Precision': precision,\n",
    "            'F1 Score': f1\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/home/s3726266/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/vol/home/s3726266/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/vol/home/s3726266/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>analyzer=word, ngram_range=(1, 1)</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.839604</td>\n",
       "      <td>0.834515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>analyzer=word, ngram_range=(1, 2)</td>\n",
       "      <td>0.838555</td>\n",
       "      <td>0.838555</td>\n",
       "      <td>0.845291</td>\n",
       "      <td>0.838780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>analyzer=word, ngram_range=(2, 2)</td>\n",
       "      <td>0.771907</td>\n",
       "      <td>0.771907</td>\n",
       "      <td>0.789605</td>\n",
       "      <td>0.775060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>analyzer=word, ngram_range=(2, 3)</td>\n",
       "      <td>0.759161</td>\n",
       "      <td>0.759161</td>\n",
       "      <td>0.780599</td>\n",
       "      <td>0.762704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>analyzer=word, ngram_range=(3, 3)</td>\n",
       "      <td>0.678837</td>\n",
       "      <td>0.678837</td>\n",
       "      <td>0.729252</td>\n",
       "      <td>0.690051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>analyzer=char, ngram_range=(1, 1)</td>\n",
       "      <td>0.245751</td>\n",
       "      <td>0.245751</td>\n",
       "      <td>0.254562</td>\n",
       "      <td>0.223204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>analyzer=char, ngram_range=(1, 2)</td>\n",
       "      <td>0.483935</td>\n",
       "      <td>0.483935</td>\n",
       "      <td>0.518863</td>\n",
       "      <td>0.477514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>analyzer=char, ngram_range=(2, 2)</td>\n",
       "      <td>0.617764</td>\n",
       "      <td>0.617764</td>\n",
       "      <td>0.630332</td>\n",
       "      <td>0.617491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>analyzer=char, ngram_range=(2, 3)</td>\n",
       "      <td>0.723845</td>\n",
       "      <td>0.723845</td>\n",
       "      <td>0.741471</td>\n",
       "      <td>0.726485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>analyzer=char, ngram_range=(3, 3)</td>\n",
       "      <td>0.739246</td>\n",
       "      <td>0.739246</td>\n",
       "      <td>0.757595</td>\n",
       "      <td>0.742628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>analyzer=char_wb, ngram_range=(1, 1)</td>\n",
       "      <td>0.196362</td>\n",
       "      <td>0.196362</td>\n",
       "      <td>0.203998</td>\n",
       "      <td>0.161199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>analyzer=char_wb, ngram_range=(1, 2)</td>\n",
       "      <td>0.374137</td>\n",
       "      <td>0.374137</td>\n",
       "      <td>0.424684</td>\n",
       "      <td>0.364851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>analyzer=char_wb, ngram_range=(2, 2)</td>\n",
       "      <td>0.613117</td>\n",
       "      <td>0.613117</td>\n",
       "      <td>0.625243</td>\n",
       "      <td>0.612642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>analyzer=char_wb, ngram_range=(2, 3)</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.720393</td>\n",
       "      <td>0.738128</td>\n",
       "      <td>0.723137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>analyzer=char_wb, ngram_range=(3, 3)</td>\n",
       "      <td>0.736856</td>\n",
       "      <td>0.736856</td>\n",
       "      <td>0.756122</td>\n",
       "      <td>0.740421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Parameter  Accuracy    Recall  Precision  \\\n",
       "0      analyzer=word, ngram_range=(1, 1)  0.834705  0.834705   0.839604   \n",
       "1      analyzer=word, ngram_range=(1, 2)  0.838555  0.838555   0.845291   \n",
       "2      analyzer=word, ngram_range=(2, 2)  0.771907  0.771907   0.789605   \n",
       "3      analyzer=word, ngram_range=(2, 3)  0.759161  0.759161   0.780599   \n",
       "4      analyzer=word, ngram_range=(3, 3)  0.678837  0.678837   0.729252   \n",
       "5      analyzer=char, ngram_range=(1, 1)  0.245751  0.245751   0.254562   \n",
       "6      analyzer=char, ngram_range=(1, 2)  0.483935  0.483935   0.518863   \n",
       "7      analyzer=char, ngram_range=(2, 2)  0.617764  0.617764   0.630332   \n",
       "8      analyzer=char, ngram_range=(2, 3)  0.723845  0.723845   0.741471   \n",
       "9      analyzer=char, ngram_range=(3, 3)  0.739246  0.739246   0.757595   \n",
       "10  analyzer=char_wb, ngram_range=(1, 1)  0.196362  0.196362   0.203998   \n",
       "11  analyzer=char_wb, ngram_range=(1, 2)  0.374137  0.374137   0.424684   \n",
       "12  analyzer=char_wb, ngram_range=(2, 2)  0.613117  0.613117   0.625243   \n",
       "13  analyzer=char_wb, ngram_range=(2, 3)  0.720393  0.720393   0.738128   \n",
       "14  analyzer=char_wb, ngram_range=(3, 3)  0.736856  0.736856   0.756122   \n",
       "\n",
       "    F1 Score  \n",
       "0   0.834515  \n",
       "1   0.838780  \n",
       "2   0.775060  \n",
       "3   0.762704  \n",
       "4   0.690051  \n",
       "5   0.223204  \n",
       "6   0.477514  \n",
       "7   0.617491  \n",
       "8   0.726485  \n",
       "9   0.742628  \n",
       "10  0.161199  \n",
       "11  0.364851  \n",
       "12  0.612642  \n",
       "13  0.723137  \n",
       "14  0.740421  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# analyzer + ngram_range\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "\n",
    "svm_classifier = svm.SVC(kernel='linear')\n",
    "parameter_sets = [\n",
    "    ('analyzer', ['word', 'char', 'char_wb']),\n",
    "    ('ngram_range', [(1, 1), (1, 2), (2, 2), (2, 3), (3, 3)])\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop through parameter combinations\n",
    "for analyzer_value in ['word', 'char', 'char_wb']:\n",
    "    for ngram_value in [(1, 1), (1, 2), (2, 2), (2, 3), (3, 3)]:\n",
    "        vectorizer = CountVectorizer(analyzer=analyzer_value, ngram_range=ngram_value)\n",
    "\n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "        # Create a pipeline\n",
    "        text_clf = Pipeline([\n",
    "            ('vect', vectorizer),\n",
    "            ('tfidf', tfidf_transformer),\n",
    "            ('clf', svm_classifier),\n",
    "        ])\n",
    "\n",
    "        text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "        twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "        docs_test = twenty_test.data\n",
    "        predicted = text_clf.predict(docs_test)\n",
    "\n",
    "        # Calculate accuracy, recall, precision, and F1 score\n",
    "        accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "        recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "        precision = precision_score(twenty_test.target, predicted, average='weighted', zero_division='warn')\n",
    "        f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "        # Store results in a dictionary\n",
    "        result = {\n",
    "            'Parameter': f\"analyzer={analyzer_value}, ngram_range={ngram_value}\",\n",
    "            'Accuracy': accuracy,\n",
    "            'Recall': recall,\n",
    "            'Precision': precision,\n",
    "            'F1 Score': f1\n",
    "        }\n",
    "        results.append(result)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Parameter</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>max_features=10000</td>\n",
       "      <td>0.812268</td>\n",
       "      <td>0.812268</td>\n",
       "      <td>0.817907</td>\n",
       "      <td>0.812612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>max_features=200000</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.839604</td>\n",
       "      <td>0.834515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>max_features=5000000</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.834705</td>\n",
       "      <td>0.839604</td>\n",
       "      <td>0.834515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Parameter  Accuracy    Recall  Precision  F1 Score\n",
       "0    max_features=10000  0.812268  0.812268   0.817907  0.812612\n",
       "1   max_features=200000  0.834705  0.834705   0.839604  0.834515\n",
       "2  max_features=5000000  0.834705  0.834705   0.839604  0.834515"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max_features\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "\n",
    "svm_classifier = svm.SVC(kernel='linear')\n",
    "max_features_values = [10000, 200000, 5000000]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Loop through max_features values\n",
    "for max_features_value in max_features_values:\n",
    "    vectorizer = CountVectorizer(max_features=max_features_value)\n",
    "\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "    # Create a pipeline\n",
    "    text_clf = Pipeline([\n",
    "        ('vect', vectorizer),\n",
    "        ('tfidf', tfidf_transformer),\n",
    "        ('clf', svm_classifier),\n",
    "    ])\n",
    "\n",
    "    text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "    twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "    docs_test = twenty_test.data\n",
    "    predicted = text_clf.predict(docs_test)\n",
    "\n",
    "    # Calculate accuracy, recall, precision, and F1 score\n",
    "    accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "    recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "    precision = precision_score(twenty_test.target, predicted, average='weighted', zero_division='warn')\n",
    "    f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "    # Store results in a dictionary\n",
    "    result = {\n",
    "        'Parameter': f\"max_features={max_features_value}\",\n",
    "        'Accuracy': accuracy,\n",
    "        'Recall': recall,\n",
    "        'Precision': precision,\n",
    "        'F1 Score': f1\n",
    "    }\n",
    "    results.append(result)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best parameteres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8335\n",
      "Recall: 0.8335\n",
      "Precision: 0.8399\n",
      "F1 Score: 0.8337\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Define the best parameters\n",
    "best_analyzer = 'word'\n",
    "best_ngram_range = (1, 2)\n",
    "best_stop_words = None  # Conflict when set to 'english'\n",
    "best_lowercasing = True\n",
    "best_max_features = 200000\n",
    "\n",
    "svm_classifier = svm.SVC(kernel='linear')\n",
    "# Create a pipeline with the best parameters\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer=best_analyzer,\n",
    "    ngram_range=best_ngram_range,\n",
    "    stop_words=best_stop_words,\n",
    "    lowercase=best_lowercasing,\n",
    "    max_features=best_max_features\n",
    ")\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('tfidf', tfidf_transformer),\n",
    "    ('clf', svm_classifier),\n",
    "])\n",
    "\n",
    "# Load data\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)\n",
    "\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)\n",
    "predicted = text_clf.predict(twenty_test.data)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(twenty_test.target, predicted)\n",
    "recall = recall_score(twenty_test.target, predicted, average='weighted')\n",
    "precision = precision_score(twenty_test.target, predicted, average='weighted', zero_division='warn')\n",
    "f1 = f1_score(twenty_test.target, predicted, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
